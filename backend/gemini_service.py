"""Gemini API æœåŠ¡æ¨¡å—"""
import os
import json
from typing import Optional, AsyncGenerator
from google import genai
from config import GEMINI_API_KEY

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY æœªé…ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®")

client = genai.Client(api_key=GEMINI_API_KEY)

# è¶…æ—¶æ—¶é—´ï¼š5åˆ†é’Ÿï¼ˆ300ç§’ï¼‰
API_TIMEOUT_MS = 300000


def generate_full_outline(
    title: str,
    genre: str,
    synopsis: str,
    progress_callback=None
) -> dict:
    """ç”Ÿæˆå®Œæ•´å¤§çº²å’Œå·ç»“æ„"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹ç”Ÿæˆå®Œæ•´å¤§çº²...")
        
        # ç”Ÿæˆå®Œæ•´å¤§çº²
        outline_prompt = f"""ä½œä¸ºä¸€åèµ„æ·±å°è¯´å®¶ï¼Œè¯·ä¸ºæ ‡é¢˜ä¸ºã€Š{title}ã€‹çš„å°è¯´åˆ›ä½œä¸€ä»½å®Œæ•´çš„æ•…äº‹å¤§çº²ã€‚
ç±»å‹ï¼š{genre}ã€‚
åˆå§‹åˆ›æ„ï¼š{synopsis}ã€‚
è¯·æä¾›å¤šå¹•ç»“æ„ã€å…³é”®æƒ…èŠ‚è½¬æŠ˜ï¼Œä»¥åŠä»å¼€å¤´åˆ°ç»“å°¾çš„é€»è¾‘å‘å±•ã€‚"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=outline_prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 8192,
            }
        )
        
        full_outline = response.text if response.text else ""
        
        if progress_callback:
            progress_callback.update(50, "å®Œæ•´å¤§çº²ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå·ç»“æ„...")
        
        # ç”Ÿæˆå·ç»“æ„
        volumes_prompt = f"""åŸºäºä»¥ä¸‹å®Œæ•´å¤§çº²ï¼Œå°†æ•…äº‹åˆ’åˆ†ä¸ºå¤šä¸ªå·ï¼ˆé€šå¸¸3-5å·ï¼‰ã€‚
å®Œæ•´å¤§çº²ï¼š{full_outline[:2000]}

è¯·ä¸ºæ¯ä¸ªå·ç”Ÿæˆæ ‡é¢˜å’Œç®€è¦æè¿°ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
- "title"ï¼ˆå·æ ‡é¢˜ï¼‰
- "summary"ï¼ˆå·çš„ç®€è¦æè¿°ï¼Œ50-100å­—ï¼‰"""
        
        volumes_response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=volumes_prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        volumes_data = None
        if volumes_response.text:
            try:
                volumes_data = json.loads(volumes_response.text)
                if not isinstance(volumes_data, list):
                    volumes_data = None
            except:
                volumes_data = None
        
        if progress_callback:
            progress_callback.update(90, "å·ç»“æ„ç”Ÿæˆå®Œæˆï¼Œå¤„ç†ç»“æœ...")
        
        result = {
            "outline": full_outline,
            "volumes": volumes_data
        }
        
        if progress_callback:
            progress_callback.update(100, "ç”Ÿæˆå®Œæˆ")
        
        return result
    except Exception as e:
        raise Exception(f"ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}")


def generate_volume_outline_stream(
    novel_title: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    characters: list,
    volume_index: int
):
    """ç”Ÿæˆå·è¯¦ç»†å¤§çº²ï¼ˆæµå¼ï¼‰"""
    try:
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        volume_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºã€Š{novel_title}ã€‹çš„ç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆè¯¦ç»†å¤§çº²ã€‚

å®Œæ•´å°è¯´å¤§çº²ï¼š{full_outline[:1500]}

æœ¬å·ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{volume_title}
{f'æè¿°ï¼š{volume_summary}' if volume_summary else ''}

è§’è‰²ï¼š{characters_text}

è¯·ç”Ÿæˆæœ¬å·çš„è¯¦ç»†å¤§çº²ï¼ŒåŒ…æ‹¬ï¼š
1. æœ¬å·çš„ä¸»è¦æƒ…èŠ‚çº¿
2. å…³é”®äº‹ä»¶å’Œè½¬æŠ˜ç‚¹
3. è§’è‰²åœ¨æœ¬å·ä¸­çš„å‘å±•
4. æœ¬å·çš„èµ·æ‰¿è½¬åˆç»“æ„

é‡è¦ï¼šè¯·æ ¹æ®æ€»çº²ä¸­æœ¬å·çš„å†…å®¹é‡ï¼Œè§„åˆ’æœ¬å·çš„å­—æ•°å’Œç« èŠ‚æ•°ã€‚
- åˆ†ææœ¬å·åœ¨æ€»çº²ä¸­çš„æƒ…èŠ‚å¤æ‚åº¦ã€äº‹ä»¶æ•°é‡å’Œå†…å®¹é‡
- ä¼°ç®—æœ¬å·çš„åˆç†å­—æ•°èŒƒå›´ï¼ˆé€šå¸¸æ¯å·15-30ä¸‡å­—ï¼‰
- æ ¹æ®å­—æ•°è§„åˆ’ç« èŠ‚æ•°ï¼ˆæ¯ç« 5000-8000å­—ï¼Œå³0.5-0.8ä¸‡å­—ï¼‰
- è®¡ç®—å…¬å¼ï¼šç« èŠ‚æ•° = å·æ€»å­—æ•°ï¼ˆä¸‡å­—ï¼‰Ã· 0.65ï¼ˆå¹³å‡æ¯ç« 0.65ä¸‡å­—ï¼‰
- ç¡®ä¿ç« èŠ‚æ•°é‡åˆç†ï¼Œæ—¢èƒ½å……åˆ†å±•å¼€æƒ…èŠ‚ï¼Œåˆä¸ä¼šè¿‡äºå†—é•¿

è¯·åœ¨å¤§çº²æœ«å°¾æ˜ç¡®æ ‡æ³¨ï¼š
ã€å­—æ•°è§„åˆ’ã€‘ï¼šXX-XXä¸‡å­—ï¼ˆä¾‹å¦‚ï¼š18-22ä¸‡å­—ï¼‰
ã€ç« èŠ‚è§„åˆ’ã€‘ï¼šXXç« ï¼ˆä¾‹å¦‚ï¼š12ç« ï¼Œå¿…é¡»æ˜¯å…·ä½“æ•°å­—ï¼Œä¸è¦èŒƒå›´ï¼‰"""
        
        stream = client.models.generate_content_stream(
            model="gemini-3-pro-preview",
            contents=volume_prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 8192,
            }
        )
        
        for chunk in stream:
            if chunk.text:
                # æŒ‰ç…§ SSE æ ¼å¼è¿”å›æ•°æ®
                data = json.dumps({"chunk": chunk.text})
                yield f"data: {data}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'done': True})}\n\n"
                
    except Exception as e:
        # å‘é€é”™è¯¯ä¿¡æ¯
        error_data = json.dumps({"error": str(e)})
        yield f"data: {error_data}\n\n"
        raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {str(e)}")


def generate_volume_outline(
    novel_title: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    characters: list,
    volume_index: int,
    progress_callback=None
) -> str:
    """ç”Ÿæˆå·è¯¦ç»†å¤§çº²ï¼ˆéæµå¼ï¼Œè¿”å›å®Œæ•´æ–‡æœ¬ï¼‰"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹ç”Ÿæˆå·å¤§çº²...")
        
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        volume_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºã€Š{novel_title}ã€‹çš„ç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆè¯¦ç»†å¤§çº²ã€‚

å®Œæ•´å°è¯´å¤§çº²ï¼š{full_outline[:1500]}

æœ¬å·ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{volume_title}
{f'æè¿°ï¼š{volume_summary}' if volume_summary else ''}

è§’è‰²ï¼š{characters_text}

è¯·ç”Ÿæˆæœ¬å·çš„è¯¦ç»†å¤§çº²ï¼ŒåŒ…æ‹¬ï¼š
1. æœ¬å·çš„ä¸»è¦æƒ…èŠ‚çº¿
2. å…³é”®äº‹ä»¶å’Œè½¬æŠ˜ç‚¹
3. è§’è‰²åœ¨æœ¬å·ä¸­çš„å‘å±•
4. æœ¬å·çš„èµ·æ‰¿è½¬åˆç»“æ„

é‡è¦ï¼šè¯·æ ¹æ®æ€»çº²ä¸­æœ¬å·çš„å†…å®¹é‡ï¼Œè§„åˆ’æœ¬å·çš„å­—æ•°å’Œç« èŠ‚æ•°ã€‚
- åˆ†ææœ¬å·åœ¨æ€»çº²ä¸­çš„æƒ…èŠ‚å¤æ‚åº¦ã€äº‹ä»¶æ•°é‡å’Œå†…å®¹é‡
- ä¼°ç®—æœ¬å·çš„åˆç†å­—æ•°èŒƒå›´ï¼ˆé€šå¸¸æ¯å·15-30ä¸‡å­—ï¼‰
- æ ¹æ®å­—æ•°è§„åˆ’ç« èŠ‚æ•°ï¼ˆæ¯ç« 5000-8000å­—ï¼Œå³0.5-0.8ä¸‡å­—ï¼‰
- è®¡ç®—å…¬å¼ï¼šç« èŠ‚æ•° = å·æ€»å­—æ•°ï¼ˆä¸‡å­—ï¼‰Ã· 0.65ï¼ˆå¹³å‡æ¯ç« 0.65ä¸‡å­—ï¼‰
- ç¡®ä¿ç« èŠ‚æ•°é‡åˆç†ï¼Œæ—¢èƒ½å……åˆ†å±•å¼€æƒ…èŠ‚ï¼Œåˆä¸ä¼šè¿‡äºå†—é•¿

è¯·åœ¨å¤§çº²æœ«å°¾æ˜ç¡®æ ‡æ³¨ï¼š
ã€å­—æ•°è§„åˆ’ã€‘ï¼šXX-XXä¸‡å­—ï¼ˆä¾‹å¦‚ï¼š18-22ä¸‡å­—ï¼‰
ã€ç« èŠ‚è§„åˆ’ã€‘ï¼šXXç« ï¼ˆä¾‹å¦‚ï¼š12ç« ï¼Œå¿…é¡»æ˜¯å…·ä½“æ•°å­—ï¼Œä¸è¦èŒƒå›´ï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨AIç”Ÿæˆå·å¤§çº²...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=volume_prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 8192,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(90, "å·å¤§çº²ç”Ÿæˆå®Œæˆ")
        
        return response.text
                
    except Exception as e:
        raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {str(e)}")


def generate_chapter_outline(
    novel_title: str,
    genre: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    volume_outline: str,
    characters: list,
    volume_index: int,
    chapter_count: Optional[int] = None
) -> list:
    """ç”Ÿæˆç« èŠ‚åˆ—è¡¨"""
    try:
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        # æå–å­—æ•°è§„åˆ’å’Œç« èŠ‚è§„åˆ’
        word_count_info = ""
        if volume_outline:
            import re
            word_match = re.search(r'ã€å­—æ•°è§„åˆ’ã€‘ï¼š\s*(\d+)[-~]?(\d+)?\s*ä¸‡å­—', volume_outline)
            if word_match:
                min_w = word_match.group(1)
                max_w = word_match.group(2) if word_match.group(2) else min_w
                word_count_info = f"\nå­—æ•°è§„åˆ’ï¼š{min_w}-{max_w}ä¸‡å­—" if max_w != min_w else f"\nå­—æ•°è§„åˆ’ï¼š{min_w}ä¸‡å­—"
        
        chapter_count_instruction = ""
        if chapter_count:
            chapter_count_instruction = f"è¯·ä¸ºæœ¬å·ç”Ÿæˆ {chapter_count} ä¸ªç« èŠ‚ã€‚"
        else:
            chapter_count_instruction = """è¯·ä»”ç»†åˆ†ææœ¬å·çš„è¯¦ç»†å¤§çº²ï¼Œæ ¹æ®ä»¥ä¸‹åŸåˆ™ç¡®å®šåˆé€‚çš„ç« èŠ‚æ•°é‡å¹¶ç”Ÿæˆç« èŠ‚åˆ—è¡¨ï¼š
ç« èŠ‚æ•°é‡åº”è¯¥ï¼š
1. ä¼˜å…ˆå‚è€ƒå·å¤§çº²ä¸­æ ‡æ³¨çš„ã€ç« èŠ‚è§„åˆ’ã€‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
2. æ ¹æ®å·å¤§çº²çš„å†…å®¹å¤æ‚åº¦å’Œå­—æ•°è§„åˆ’åˆç†åˆ†é…
3. ç¡®ä¿æ¯ä¸ªç« èŠ‚æœ‰è¶³å¤Ÿçš„å†…å®¹å’Œæƒ…èŠ‚å‘å±•ï¼ˆæ¯ç« 5000-8000å­—ï¼Œå³0.5-0.8ä¸‡å­—ï¼‰
4. å¦‚æœå¤§çº²ä¸­æœ‰å­—æ•°è§„åˆ’ï¼ŒæŒ‰ç…§æ¯ç« 5000-8000å­—çš„æ ‡å‡†è®¡ç®—ç« èŠ‚æ•°
5. å¦‚æœå¤§çº²ä¸­æ˜ç¡®æåˆ°äº†ç« èŠ‚æ•°ï¼Œè¯·å‚è€ƒè¯¥æ•°é‡
6. å¦‚æœå¤§çº²ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°ï¼Œè¯·æ ¹æ®æƒ…èŠ‚ç»“æ„åˆç†åˆ†é…ï¼ˆé€šå¸¸æ¯ç« å¯¹åº”ä¸€ä¸ªä¸»è¦äº‹ä»¶æˆ–æƒ…èŠ‚è½¬æŠ˜ç‚¹ï¼‰
7. ç« èŠ‚æ•°é‡åº”åœ¨åˆç†èŒƒå›´å†…ï¼ˆå»ºè®®6-30ç« ï¼‰"""
        
        volume_desc = f"å·æè¿°ï¼š{volume_summary[:200]}" if volume_summary else ""
        volume_outline_text = f"å·è¯¦ç»†å¤§çº²ï¼š{volume_outline[:1500]}" if volume_outline else ""
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œä¸ºç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆç« èŠ‚åˆ—è¡¨ï¼š
æ ‡é¢˜ï¼š{novel_title}
ç±»å‹ï¼š{genre}
å®Œæ•´å¤§çº²ï¼š{full_outline[:800]}

æœ¬å·ä¿¡æ¯ï¼š
{volume_desc}
{volume_outline_text}{word_count_info}

è§’è‰²ï¼š{characters_text}

{chapter_count_instruction}

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š"title"ï¼ˆæ ‡é¢˜ï¼‰ã€"summary"ï¼ˆæ‘˜è¦ï¼‰ã€"aiPromptHints"ï¼ˆAIæç¤ºï¼‰ã€‚"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        chapters = json.loads(response.text)
        if not isinstance(chapters, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        return chapters
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")


def write_chapter_content_stream(
    novel_title: str,
    genre: str,
    synopsis: str,
    chapter_title: str,
    chapter_summary: str,
    chapter_prompt_hints: str,
    characters: list,
    world_settings: list,
    previous_chapters_context: Optional[str] = None,
    novel_id: Optional[str] = None,
    current_chapter_id: Optional[str] = None,
    db_session=None
):
    """ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆæµå¼ï¼‰"""
    try:
        characters_text = "ï¼›".join([f"{c.get('name', '')}ï¼š{c.get('personality', '')}" for c in characters]) if characters else "æš‚æ— "
        world_text = "ï¼›".join([f"{w.get('title', '')}ï¼š{w.get('description', '')}" for w in world_settings]) if world_settings else "æš‚æ— "
        
        # æ–°å¢ï¼šä½¿ç”¨å‘é‡æ£€ç´¢è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæä¾›äº† novel_id å’Œ db_sessionï¼‰
        if novel_id and db_session:
            try:
                from services.consistency_checker import ConsistencyChecker
                from services.content_similarity_checker import ContentSimilarityChecker
                
                # å¯é€‰ï¼šåœ¨ç”Ÿæˆå‰è¿›è¡Œç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆä»…è­¦å‘Šï¼Œä¸é˜»æ­¢ç”Ÿæˆï¼‰
                try:
                    similarity_checker = ContentSimilarityChecker()
                    similarity_result = similarity_checker.check_before_generation(
                        db=db_session,
                        novel_id=novel_id,
                        chapter_title=chapter_title,
                        chapter_summary=chapter_summary,
                        exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                        similarity_threshold=0.8
                    )
                    if similarity_result.get("has_similar_content"):
                        import logging
                        logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦è­¦å‘Š: {similarity_result.get('warnings', [])}")
                except Exception as e:
                    import logging
                    logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦æ£€æŸ¥å¤±è´¥ï¼ˆç»§ç»­ç”Ÿæˆï¼‰: {str(e)}")
                
                # è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡ï¼ˆå¢åŠ åˆ°5ç« ä»¥æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ï¼Œé¿å…é‡å¤ï¼‰
                checker = ConsistencyChecker()
                smart_context = checker.get_relevant_context_text(
                    db=db_session,
                    novel_id=novel_id,
                    current_chapter_title=chapter_title,
                    current_chapter_summary=chapter_summary,
                    exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                    max_chapters=5
                )
                
                if smart_context and smart_context.strip():
                    previous_chapters_context = smart_context
                    import logging
                    logging.getLogger(__name__).info(f"âœ… ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼Œæ‰¾åˆ° {len(smart_context.split('---'))} ä¸ªç›¸å…³ç« èŠ‚")
            except Exception as e:
                # å¦‚æœå‘é‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡ï¼Œä¸å½±å“ä¸»æµç¨‹
                import logging
                logging.getLogger(__name__).warning(f"âš ï¸  æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡: {str(e)}")
        
        # æ„å»ºå‰æ–‡ä¸Šä¸‹æ–‡éƒ¨åˆ†ï¼ˆå¢å¼ºç‰ˆï¼Œæ›´å¼ºè°ƒé¿å…é‡å¤ï¼‰
        previous_context_section = ""
        if previous_chapters_context and previous_chapters_context.strip():
            previous_context_section = f"""

ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦æ™ºèƒ½æ¨èçš„ç›¸å…³ç« èŠ‚ï¼‰ï¼š
{previous_chapters_context}

ğŸš¨ ã€é‡å¤å†…å®¹æ£€æŸ¥è¦æ±‚ã€‘- å¿…é¡»ä¸¥æ ¼éµå®ˆï¼š
1. âŒ ç»å¯¹ç¦æ­¢ï¼šé‡å¤å‰æ–‡ä¸­å·²ç»å®Œæ•´æè¿°è¿‡çš„åœºæ™¯ã€äº‹ä»¶ã€å¯¹è¯
2. âŒ ç»å¯¹ç¦æ­¢ï¼šä½¿ç”¨ä¸å‰æ–‡ç›¸åŒçš„å™äº‹ç»“æ„ã€æå†™æ‰‹æ³•ã€è¯­è¨€é£æ ¼
3. âŒ ç»å¯¹ç¦æ­¢ï¼šè®©è§’è‰²é‡å¤åšè¿‡çš„äº‹æƒ…æˆ–è¯´è¿‡ç±»ä¼¼çš„è¯
4. âœ… æ­£ç¡®åšæ³•ï¼šå¦‚éœ€æåŠå‰æ–‡ï¼Œä»…ç”¨1-2å¥ç®€çŸ­è¿‡æ¸¡ï¼Œä¸å±•å¼€æå†™
5. âœ… æ­£ç¡®åšæ³•ï¼šæœ¬ç« å¿…é¡»æ¨è¿›å…¨æ–°æƒ…èŠ‚ï¼Œå±•ç°æ–°çš„å†²çªå’Œå‘å±•
6. âœ… æ­£ç¡®åšæ³•ï¼šé‡‡ç”¨ä¸åŒçš„å™è¿°è§†è§’ã€æƒ…ç»ªåŸºè°ƒã€æå†™é‡ç‚¹
7. âœ… æ­£ç¡®åšæ³•ï¼šç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æ ¸å¿ƒäº‹ä»¶ï¼Œä¸å‰æ–‡æ˜æ˜¾åŒºåˆ†

âš ï¸ æ³¨æ„ï¼šä¸Šè¿°å‰æ–‡æ˜¯é€šè¿‡AIè¯­ä¹‰åˆ†æè‡ªåŠ¨æ¨èçš„æœ€ç›¸å…³ç« èŠ‚ï¼Œè¯·è®¤çœŸé˜…è¯»å¹¶ç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨ä¸åŒã€‚
"""
        
        prompt = f"""è¯·ä¸ºå°è¯´ã€Š{novel_title}ã€‹åˆ›ä½œä¸€ä¸ªå®Œæ•´çš„ç« èŠ‚ã€‚

ã€ç« èŠ‚åŸºæœ¬ä¿¡æ¯ã€‘
- æ ‡é¢˜ï¼š{chapter_title}
- æƒ…èŠ‚æ‘˜è¦ï¼š{chapter_summary}
- å†™ä½œæç¤ºï¼š{chapter_prompt_hints}

ã€å°è¯´èƒŒæ™¯ä¿¡æ¯ã€‘
- å®Œæ•´ç®€ä»‹ï¼š{synopsis}
- æ¶‰åŠè§’è‰²ï¼š{characters_text}
- ä¸–ç•Œè§‚è§„åˆ™ï¼š{world_text}
{previous_context_section}

ã€åˆ›ä½œè¦æ±‚ã€‘
1. å­—æ•°è¦æ±‚ï¼š5000-8000å­—ï¼ˆæ­£æ–‡å†…å®¹ï¼Œå……å®é¥±æ»¡ï¼‰
2. æƒ…èŠ‚è¦æ±‚ï¼š
   - å¿…é¡»å®Œæ•´æ¨è¿›æœ¬ç« æƒ…èŠ‚ï¼Œæœ‰æ˜ç¡®çš„å¼€ç«¯ã€å‘å±•ã€é«˜æ½®ã€ç»“å°¾
   - æ ¸å¿ƒäº‹ä»¶å¿…é¡»ä¸å‰æ–‡ä¸åŒï¼Œé¿å…é‡å¤æƒ…èŠ‚
   - ç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æˆå‰§å†²çªå’Œæƒ…æ„Ÿå¼ åŠ›
3. å™äº‹è¦æ±‚ï¼š
   - é‡‡ç”¨é«˜æ–‡å­¦å“è´¨çš„æ²‰æµ¸å¼æè¿°
   - å¯¹è¯è¦ç”ŸåŠ¨è‡ªç„¶ï¼Œç¬¦åˆè§’è‰²æ€§æ ¼
   - ç»†èŠ‚æå†™ä¸°å¯Œï¼ˆç¯å¢ƒã€å¿ƒç†ã€åŠ¨ä½œã€ç¥æ€ï¼‰
   - å™äº‹èŠ‚å¥å¼ å¼›æœ‰åº¦ï¼Œé¿å…å¹³é“ºç›´å™
4. åŸåˆ›æ€§è¦æ±‚ï¼š
   - åœºæ™¯è®¾ç½®å¿…é¡»æ–°é¢–ç‹¬ç‰¹
   - è§’è‰²äº’åŠ¨æ–¹å¼è¦æœ‰å˜åŒ–
   - é¿å…ä½¿ç”¨å¥—è·¯åŒ–çš„è¡¨è¾¾å’Œæ¡¥æ®µ

âš ï¸ æœ€é‡è¦ï¼šè®¤çœŸé˜…è¯»ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼Œç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨åŸåˆ›ï¼Œä¸ä¸å‰æ–‡é‡å¤ï¼

ç°åœ¨è¯·å¼€å§‹åˆ›ä½œï¼Œä»…è¾“å‡ºç« èŠ‚æ­£æ–‡å†…å®¹ï¼ˆä¸è¦è¾“å‡ºæ ‡é¢˜ï¼‰ï¼š"""
        
        stream = client.models.generate_content_stream(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "temperature": 0.9,
                "max_output_tokens": 16384,
            }
        )
        
        for chunk in stream:
            if chunk.text:
                # æŒ‰ç…§ SSE æ ¼å¼è¿”å›æ•°æ®
                data = json.dumps({"chunk": chunk.text})
                yield f"data: {data}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'done': True})}\n\n"
                
    except Exception as e:
        # å‘é€é”™è¯¯ä¿¡æ¯
        error_data = json.dumps({"error": str(e)})
        yield f"data: {error_data}\n\n"
        raise Exception(f"ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {str(e)}")


def generate_characters(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆè§’è‰²åˆ—è¡¨"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆè§’è‰²åˆ—è¡¨...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¸»è¦è§’è‰²åˆ—è¡¨ï¼ˆ3-8ä¸ªè§’è‰²ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªè§’è‰²ç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "name"ï¼ˆå§“åï¼‰
- "age"ï¼ˆå¹´é¾„ï¼‰
- "role"ï¼ˆè§’è‰²å®šä½ï¼Œå¦‚ï¼šä¸»è§’ã€åæ´¾ã€é…è§’ç­‰ï¼‰
- "personality"ï¼ˆæ€§æ ¼ç‰¹å¾ï¼‰
- "background"ï¼ˆèƒŒæ™¯æ•…äº‹ï¼‰
- "goals"ï¼ˆç›®æ ‡å’ŒåŠ¨æœºï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆè§’è‰²...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†è§’è‰²æ•°æ®...")
        
        characters = json.loads(response.text)
        if not isinstance(characters, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "è§’è‰²ç”Ÿæˆå®Œæˆ")
        
        return characters
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆè§’è‰²åˆ—è¡¨å¤±è´¥: {str(e)}")


def generate_world_settings(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆä¸–ç•Œè§‚è®¾å®š"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆä¸–ç•Œè§‚è®¾å®š...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆ5-10ä¸ªè®¾å®šï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªè®¾å®šç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "title"ï¼ˆè®¾å®šæ ‡é¢˜ï¼‰
- "category"ï¼ˆåˆ†ç±»ï¼šåœ°ç†ã€ç¤¾ä¼šã€é­”æ³•/ç§‘æŠ€ã€å†å²ã€å…¶ä»–ï¼‰
- "description"ï¼ˆè¯¦ç»†æè¿°ï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆä¸–ç•Œè§‚...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†ä¸–ç•Œè§‚æ•°æ®...")
        
        settings = json.loads(response.text)
        if not isinstance(settings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "ä¸–ç•Œè§‚ç”Ÿæˆå®Œæˆ")
        
        return settings
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆä¸–ç•Œè§‚è®¾å®šå¤±è´¥: {str(e)}")


def generate_timeline_events(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆé‡è¦æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆ5-10ä¸ªäº‹ä»¶ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªäº‹ä»¶ç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "time"ï¼ˆæ—¶é—´/å¹´ä»£ï¼‰
- "event"ï¼ˆäº‹ä»¶æ ‡é¢˜ï¼‰
- "impact"ï¼ˆäº‹ä»¶å½±å“å’Œåæœï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆæ—¶é—´çº¿...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†æ—¶é—´çº¿æ•°æ®...")
        
        events = json.loads(response.text)
        if not isinstance(events, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ")
        
        return events
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶å¤±è´¥: {str(e)}")


def generate_foreshadowings_from_outline(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ä»å¤§çº²ä¸­ç”Ÿæˆä¼ç¬”"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆä¼ç¬”åˆ—è¡¨...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¼ç¬”åˆ—è¡¨ï¼ˆ5-15ä¸ªä¼ç¬”ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:2000]}

è¯·åˆ†ææ•…äº‹å¤§çº²ï¼Œè¯†åˆ«å…¶ä¸­çš„ä¼ç¬”çº¿ç´¢ã€‚ä¼ç¬”æ˜¯æŒ‡åœ¨æ•…äº‹æ—©æœŸåŸ‹ä¸‹çš„çº¿ç´¢ï¼Œä¼šåœ¨åæœŸå¾—åˆ°å‘¼åº”æˆ–æ­ç¤ºã€‚

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "content"ï¼ˆä¼ç¬”å†…å®¹æè¿°ï¼Œ50-150å­—ï¼‰"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†ä¼ç¬”æ•°æ®...")
        
        foreshadowings = json.loads(response.text)
        if not isinstance(foreshadowings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "ä¼ç¬”ç”Ÿæˆå®Œæˆ")
        
        return foreshadowings
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆä¼ç¬”å¤±è´¥: {str(e)}")


def modify_outline_by_dialogue(
    title: str,
    genre: str,
    synopsis: str,
    current_outline: str,
    characters: list,
    world_settings: list,
    timeline: list,
    user_message: str,
    progress_callback=None
) -> dict:
    """é€šè¿‡å¯¹è¯ä¿®æ”¹å¤§çº²å¹¶è”åŠ¨æ›´æ–°ç›¸å…³è®¾å®š"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹åˆ†æä¿®æ”¹è¯·æ±‚...")
        
        # æ„å»ºæç¤ºè¯
        characters_text = "ï¼›".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰ï¼š{c.get('personality', '')}" for c in characters[:10]]) if characters else "æš‚æ— "
        world_text = "ï¼›".join([f"{w.get('title', '')}ï¼ˆ{w.get('category', '')}ï¼‰ï¼š{w.get('description', '')[:100]}" for w in world_settings[:10]]) if world_settings else "æš‚æ— "
        timeline_text = "ï¼›".join([f"[{t.get('time', '')}] {t.get('event', '')}" for t in timeline[:10]]) if timeline else "æš‚æ— "
        
        prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±å°è¯´ç¼–è¾‘ï¼Œç”¨æˆ·æƒ³è¦ä¿®æ”¹å°è¯´ã€Š{title}ã€‹çš„å¤§çº²ã€‚

å½“å‰å°è¯´ä¿¡æ¯ï¼š
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}

å½“å‰å®Œæ•´å¤§çº²ï¼š
{current_outline[:3000]}{'...' if len(current_outline) > 3000 else ''}

å½“å‰è§’è‰²åˆ—è¡¨ï¼š
{characters_text}

å½“å‰ä¸–ç•Œè§‚è®¾å®šï¼š
{world_text}

å½“å‰æ—¶é—´çº¿äº‹ä»¶ï¼š
{timeline_text}

ç”¨æˆ·ä¿®æ”¹è¯·æ±‚ï¼š{user_message}

è¯·æ ¹æ®ç”¨æˆ·çš„ä¿®æ”¹è¯·æ±‚ï¼Œç”Ÿæˆä¿®æ”¹åçš„å†…å®¹ã€‚ä½ éœ€è¦ï¼š
1. åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œç†è§£è¦ä¿®æ”¹çš„å†…å®¹
2. ç”Ÿæˆä¿®æ”¹åçš„å®Œæ•´å¤§çº²ï¼ˆä¿æŒåŸæœ‰ç»“æ„ï¼Œåªä¿®æ”¹éœ€è¦æ”¹å˜çš„éƒ¨åˆ†ï¼‰
3. å¦‚æœæ¶‰åŠåˆ°å·ç»“æ„çš„ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„å·åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
4. å¦‚æœæ¶‰åŠåˆ°è§’è‰²çš„æ–°å¢æˆ–ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„è§’è‰²åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
5. å¦‚æœæ¶‰åŠåˆ°ä¸–ç•Œè§‚çš„ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„ä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
6. å¦‚æœæ¶‰åŠåˆ°æ—¶é—´çº¿çš„è°ƒæ•´ï¼Œç”Ÿæˆæ›´æ–°åçš„æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
7. ç”Ÿæˆä¸€ä¸ªå˜æ›´è¯´æ˜åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå˜æ›´æè¿°å­—ç¬¦ä¸²ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "outline": ä¿®æ”¹åçš„å®Œæ•´å¤§çº²ï¼ˆå­—ç¬¦ä¸²ï¼‰
- "volumes": ä¿®æ”¹åçš„å·åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "title" å’Œ "summary"ï¼‰
- "characters": ä¿®æ”¹åçš„è§’è‰²åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "name", "age", "role", "personality", "background", "goals"ï¼‰
- "world_settings": ä¿®æ”¹åçš„ä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "title", "category", "description"ï¼‰
- "timeline": ä¿®æ”¹åçš„æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "time", "event", "impact"ï¼‰
- "changes": å˜æ›´è¯´æ˜åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å­—ç¬¦ä¸²ï¼‰

åªè¿”å› JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
        
        if progress_callback:
            progress_callback.update(30, "æ­£åœ¨è°ƒç”¨ AI åˆ†æå¹¶ç”Ÿæˆä¿®æ”¹æ–¹æ¡ˆ...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.8,
                "max_output_tokens": 16384,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(70, "æ­£åœ¨å¤„ç†ç”Ÿæˆç»“æœ...")
        
        result = json.loads(response.text)
        
        # ç¡®ä¿è¿”å›çš„æ•°æ®æ ¼å¼æ­£ç¡®
        if not isinstance(result, dict):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º JSON å¯¹è±¡")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if "outline" not in result:
            raise Exception("è¿”å›æ•°æ®ä¸­ç¼ºå°‘ outline å­—æ®µ")
        
        # ç¡®ä¿å¯é€‰å­—æ®µä¸ºåˆ—è¡¨æˆ– None
        if "volumes" in result and result["volumes"] is not None and not isinstance(result["volumes"], list):
            result["volumes"] = None
        if "characters" in result and result["characters"] is not None and not isinstance(result["characters"], list):
            result["characters"] = None
        if "world_settings" in result and result["world_settings"] is not None and not isinstance(result["world_settings"], list):
            result["world_settings"] = None
        if "timeline" in result and result["timeline"] is not None and not isinstance(result["timeline"], list):
            result["timeline"] = None
        if "changes" not in result or not isinstance(result.get("changes"), list):
            result["changes"] = []
        
        if progress_callback:
            progress_callback.update(100, "ä¿®æ”¹æ–¹æ¡ˆç”Ÿæˆå®Œæˆ")
        
        return result
        
    except json.JSONDecodeError as e:
        raise Exception(f"è§£æ JSON å“åº”å¤±è´¥: {str(e)}")
    except Exception as e:
        raise Exception(f"ä¿®æ”¹å¤§çº²å¤±è´¥: {str(e)}")


def extract_foreshadowings_from_chapter(
    title: str,
    genre: str,
    chapter_title: str,
    chapter_content: str,
    existing_foreshadowings: list = None
) -> list:
    """ä»ç« èŠ‚å†…å®¹ä¸­æå–ä¼ç¬”"""
    try:
        existing_text = ""
        if existing_foreshadowings:
            existing_text = "\nå·²å­˜åœ¨çš„ä¼ç¬”ï¼š\n" + "\n".join([f"- {f.get('content', '')[:100]}" for f in existing_foreshadowings[:10]])
        
        prompt = f"""åŸºäºä»¥ä¸‹ç« èŠ‚å†…å®¹ï¼Œæå–æ–°å‡ºç°çš„ä¼ç¬”çº¿ç´¢ï¼ˆ0-5ä¸ªï¼‰ï¼š
å°è¯´æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
ç« èŠ‚å†…å®¹ï¼š{chapter_content[:3000]}
{existing_text}

è¯·ä»”ç»†åˆ†æç« èŠ‚å†…å®¹ï¼Œè¯†åˆ«ï¼š
1. æ–°å‡ºç°çš„å¯ç–‘çº¿ç´¢ã€æœªè§£ä¹‹è°œ
2. è§’è‰²çš„æš—ç¤ºæ€§è¯è¯­æˆ–è¡Œä¸º
3. ç¯å¢ƒä¸­çš„ç‰¹æ®Šç»†èŠ‚
4. çœ‹ä¼¼æ— æ„ä½†å¯èƒ½æœ‰æ·±æ„çš„æƒ…èŠ‚è®¾ç½®

æ³¨æ„ï¼š
- åªæå–æ˜æ˜¾å¯ä»¥ä½œä¸ºä¼ç¬”çš„å†…å®¹
- é¿å…ä¸å·²æœ‰ä¼ç¬”é‡å¤
- å¦‚æœç« èŠ‚ä¸­æ²¡æœ‰æ–°çš„ä¼ç¬”çº¿ç´¢ï¼Œè¿”å›ç©ºæ•°ç»„

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "content"ï¼ˆä¼ç¬”å†…å®¹æè¿°ï¼Œ50-150å­—ï¼‰"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        foreshadowings = json.loads(response.text)
        if not isinstance(foreshadowings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        return foreshadowings
        
    except Exception as e:
        raise Exception(f"æå–ä¼ç¬”å¤±è´¥: {str(e)}")

