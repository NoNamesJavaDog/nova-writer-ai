"""Gemini API æœåŠ¡æ¨¡å—"""
import os
import json
import logging
from typing import Optional, AsyncGenerator
from google import genai
from core.config import GEMINI_API_KEY, GEMINI_PROXY

# åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY æœªé…ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®")

# é…ç½®ä»£ç†ï¼ˆå¦‚æœè®¾ç½®äº† GEMINI_PROXYï¼‰
# Google genai å®¢æˆ·ç«¯ä½¿ç”¨ httpxï¼Œä¼šè¯»å– HTTP_PROXY å’Œ HTTPS_PROXY ç¯å¢ƒå˜é‡
if GEMINI_PROXY:
    # ç¡®ä¿ä»£ç†åœ°å€æ ¼å¼æ­£ç¡®ï¼ˆhttp:// æˆ– https://ï¼‰
    proxy_url = GEMINI_PROXY.strip()
    if not proxy_url.startswith(('http://', 'https://', 'socks5://', 'socks5h://')):
        proxy_url = f"http://{proxy_url}"
    
    os.environ['HTTP_PROXY'] = proxy_url
    os.environ['HTTPS_PROXY'] = proxy_url
    # httpx ä¹Ÿæ”¯æŒ ALL_PROXY
    os.environ['ALL_PROXY'] = proxy_url
    
    logger = logging.getLogger(__name__)
    logger.info(f"âœ… Gemini API ä»£ç†å·²é…ç½®: {proxy_url}")
    logger.info(f"   ç¯å¢ƒå˜é‡ HTTP_PROXY={os.environ.get('HTTP_PROXY')}")
    logger.info(f"   ç¯å¢ƒå˜é‡ HTTPS_PROXY={os.environ.get('HTTPS_PROXY')}")

client = genai.Client(api_key=GEMINI_API_KEY)

# è¶…æ—¶æ—¶é—´ï¼š5åˆ†é’Ÿï¼ˆ300ç§’ï¼‰
API_TIMEOUT_MS = 300000


def generate_full_outline(
    title: str,
    genre: str,
    synopsis: str,
    progress_callback=None
) -> dict:
    """ç”Ÿæˆå®Œæ•´å¤§çº²å’Œå·ç»“æ„"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹ç”Ÿæˆå®Œæ•´å¤§çº²...")

        def ensure_text_length_range(
            text: str,
            *,
            min_chars: int,
            max_chars: int,
            title: str,
            genre: str,
            synopsis: str,
            progress_callback=None
        ) -> str:
            """ç¡®ä¿æ–‡æœ¬é•¿åº¦å¤„äºèŒƒå›´å†…ï¼›è¿‡çŸ­åˆ™æ‰©å†™ï¼Œè¿‡é•¿åˆ™å‹ç¼©ã€‚"""
            if not text:
                text = ""

            def within_range(s: str) -> bool:
                return min_chars <= len(s) <= max_chars

            # æœ€å¤šåšä¸¤æ¬¡ä¿®æ­£ï¼Œé¿å…æ­»å¾ªç¯
            for attempt in range(2):
                if within_range(text):
                    return text

                is_too_short = len(text) < min_chars
                if progress_callback:
                    action = "æ‰©å†™" if is_too_short else "å‹ç¼©"
                    progress_callback.update(
                        20 + attempt * 10,
                        f"æ­£åœ¨æŒ‰å­—æ•°è¦æ±‚{action}å¤§çº²ï¼ˆç›®æ ‡ {min_chars}-{max_chars} å­—ï¼‰..."
                    )

                refine_prompt = f"""ä½ æ˜¯èµ„æ·±å°è¯´æ€»ç¼–å‰§ã€‚è¯·å¯¹ä¸‹é¢çš„å¤§çº²è¿›è¡Œâ€œ{('æ‰©å†™' if is_too_short else 'å‹ç¼©')}ä¸æ•´ç†â€ï¼Œå¹¶ä¸¥æ ¼æ»¡è¶³å­—æ•°èŒƒå›´è¦æ±‚ã€‚

ã€ç¡¬æ€§å­—æ•°è¦æ±‚ã€‘
- æœ€ç»ˆè¾“å‡ºå¿…é¡»åœ¨ {min_chars}-{max_chars} å­—ä¹‹é—´ï¼ˆä»¥å­—ç¬¦æ•°è¿‘ä¼¼è®¡ç®—ï¼‰
- å¿…é¡»å°‘äºç­‰äº {max_chars} å­—

ã€å†…å®¹è¦æ±‚ã€‘
- ä¿ç•™å¹¶å¼ºåŒ–å¯æŒ‡å¯¼åˆ†å·/åˆ†ç« çš„ç»†èŠ‚ï¼šå› æœé“¾ã€è½¬æŠ˜ç‚¹ã€è§’è‰²æŠ‰æ‹©ã€å…³é”®äº‹ä»¶ã€ä¼ç¬”ä¸å›æ”¶
- ä¿æŒç»“æ„æ¸…æ™°ï¼ˆåˆ†çº§æ ‡é¢˜/ç¼–å·åˆ—è¡¨ï¼‰
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€å‰åå¯¹æ¯”ã€æˆ–ç»Ÿè®¡ä¿¡æ¯ï¼Œåªè¾“å‡ºæœ€ç»ˆå¤§çº²æ­£æ–‡

ã€å°è¯´ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
åˆå§‹åˆ›æ„ï¼š{synopsis}

ã€å½“å‰å¤§çº²ã€‘
{text}
"""

                refine_response = client.models.generate_content(
                    model="gemini-3-pro-preview",
                    contents=refine_prompt,
                    config={
                        "temperature": 0.3,
                        "max_output_tokens": 8192,
                    },
                )

                text = refine_response.text if refine_response.text else text

            # å…œåº•ï¼šä»ç„¶è¿‡é•¿åˆ™ç¡¬æˆªæ–­ï¼ˆå°½é‡ä¿è¯ä¸è¶…æ ‡ï¼‰
            if len(text) > max_chars:
                return text[:max_chars]
            return text

        # ç”Ÿæˆå®Œæ•´å¤§çº²
        outline_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±å°è¯´ç­–åˆ’ä¸æ€»ç¼–å‰§ï¼Œè¯·ä¸ºå°è¯´ã€Š{title}ã€‹åˆ›ä½œâ€œå°½å¯èƒ½è¯¦ç»†ã€å¯ç›´æ¥æŒ‡å¯¼åˆ†å·ä¸åˆ†ç« â€çš„å®Œæ•´å¤§çº²ã€‚

ã€ä½œå“ä¿¡æ¯ã€‘
ç±»å‹ï¼š{genre}
ä¸€å¥è¯/åˆå§‹åˆ›æ„ï¼š{synopsis}

ã€å­—æ•°è¦æ±‚ã€‘
- æœ€ç»ˆè¾“å‡ºæ§åˆ¶åœ¨ 6000-10000 å­—ä¹‹é—´ï¼ˆä¸å¾—è¶…è¿‡ 10000 å­—ï¼‰

ã€è¾“å‡ºè¦æ±‚ï¼ˆè¶Šè¯¦ç»†è¶Šå¥½ï¼‰ã€‘
1) æ•…äº‹æ ¸å¿ƒï¼ˆä¸è¶…è¿‡200å­—ï¼‰
   - æ ¸å¿ƒçŸ›ç›¾ã€ä¸»é¢˜æ¯é¢˜ã€æƒ…æ„Ÿä¸»çº¿ã€ä¸»è§’æ¬²æœ›ä¸ä»£ä»·
2) ä¸–ç•Œè§‚ä¸è§„åˆ™ï¼ˆå¯è½åœ°ï¼‰
   - å…³é”®è®¾å®š/è§„åˆ™æ¸…å•ï¼ˆè‡³å°‘10æ¡ï¼‰ï¼ŒåŒ…æ‹¬ï¼šè¾¹ç•Œã€ä»£ä»·ã€é™åˆ¶ã€å¸¸è¯†ã€æ½œè§„åˆ™
3) ä¸»è¦è§’è‰²æ¡£æ¡ˆï¼ˆè‡³å°‘6ä¸ªï¼‰
   - è§’è‰²å®šä½ã€åŠ¨æœº/ææƒ§ã€ç§˜å¯†ã€æˆé•¿å¼§çº¿ã€ä¸ä¸»è§’å…³ç³»ã€å…³é”®æŠ‰æ‹©ç‚¹
4) å…¨ä¹¦ç»“æ„ï¼ˆå¤šå¹•ç»“æ„ï¼‰
   - æŒ‰â€œåºå¹•/ç¬¬ä¸€å¹•/ç¬¬äºŒå¹•ä¸Š/ç¬¬äºŒå¹•ä¸‹/ç¬¬ä¸‰å¹•/å°¾å£°â€ç»™å‡ºï¼š
     * æ¯å¹•ç›®æ ‡ã€å¯¹æŠ—ã€è½¬æŠ˜ç‚¹ã€èƒœè´Ÿä¸ä»£ä»·
5) å…³é”®äº‹ä»¶æ—¶é—´çº¿
   - ä»¥â€œç¼–å·+äº‹ä»¶+å‚ä¸è€…+å› æœ+å¯¹åç»­å½±å“â€çš„æ–¹å¼åˆ—å‡ºè‡³å°‘25æ¡ï¼ˆä»å¼€ç«¯åˆ°ç»“å±€ï¼‰
6) ä¼ç¬”ä¸å›æ”¶ï¼ˆå¿…é¡»å¯æ‰§è¡Œï¼‰
   - ä¼ç¬”æ¸…å•ï¼ˆè‡³å°‘12æ¡ï¼‰ï¼šåŸ‹ä¸‹ä½ç½®/è¡¨ç°å½¢å¼/å›æ”¶ä½ç½®/å›æ”¶æ–¹å¼/æƒ…æ„Ÿæˆ–é€»è¾‘æ”¶ç›Š
7) åˆ†å·è§„åˆ’ï¼ˆä¸ºåç»­ç”Ÿæˆå·å¤§çº²å’Œç« èŠ‚åˆ—è¡¨æœåŠ¡ï¼‰
   - å»ºè®®å·æ•°ï¼š3-8å·ï¼ˆå¦‚æœæ•…äº‹ä½“é‡éœ€è¦ä¹Ÿå¯ä»¥æ›´å¤šï¼Œä½†å¿…é¡»è§£é‡ŠåŸå› ï¼‰
   - æ¯å·å†™æ¸…ï¼šå·ä¸»é¢˜ã€ä¸»å†²çªã€å…³é”®è½¬æŠ˜ã€é«˜æ½®ã€å·ç»“å°¾çŠ¶æ€å˜åŒ–
   - æ¯å·è‡³å°‘ç»™å‡º8-15ä¸ªâ€œå‰§æƒ…èŠ‚ç‚¹â€ï¼ˆèŠ‚ç‚¹=å¯æ‹†æˆç« èŠ‚çš„äº‹ä»¶ï¼‰ï¼Œå¹¶æ ‡æ³¨ï¼š
     * èŠ‚ç‚¹ç›®æ ‡/å†²çª/ç»“æœ/æ¨è¿›äº†ä»€ä¹ˆäººç‰©å¼§çº¿/ç•™ä¸‹æˆ–å›æ”¶äº†ä»€ä¹ˆä¼ç¬”

ã€é‡è¦çº¦æŸã€‘
- å¤§çº²å¿…é¡»è‡ªæ´½ã€å› æœæ¸…æ™°ã€å¯ç›´æ¥æ‹†åˆ†ä¸ºç« èŠ‚ï¼Œä¸è¦ç©ºæ³›å£å·
- ä¸è¦åªå†™æ¢—æ¦‚ï¼›è¦å†™â€œäº‹ä»¶é“¾+è½¬æŠ˜ç‚¹+è§’è‰²æŠ‰æ‹©â€
- ä½¿ç”¨æ¸…æ™°çš„åˆ†çº§æ ‡é¢˜ä¸ç¼–å·åˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­ç¨‹åºè§£æä¸å¼•ç”¨
"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=outline_prompt,
            config={
                "temperature": 0.75,
                "max_output_tokens": 16384,
            }
        )
        
        full_outline = response.text if response.text else ""
        full_outline = ensure_text_length_range(
            full_outline,
            min_chars=6000,
            max_chars=10000,
            title=title,
            genre=genre,
            synopsis=synopsis,
            progress_callback=progress_callback
        )
        
        if progress_callback:
            progress_callback.update(50, "å®Œæ•´å¤§çº²ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå·ç»“æ„...")
        
        # ç”Ÿæˆå·ç»“æ„
        volumes_prompt = f"""åŸºäºä»¥ä¸‹å®Œæ•´å¤§çº²ï¼Œå°†æ•…äº‹åˆ’åˆ†ä¸ºå¤šä¸ªå·ï¼ˆé€šå¸¸3-5å·ï¼‰ã€‚
å®Œæ•´å¤§çº²ï¼š{full_outline[:2000]}

è¯·ä¸ºæ¯ä¸ªå·ç”Ÿæˆæ ‡é¢˜å’Œç®€è¦æè¿°ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
- "title"ï¼ˆå·æ ‡é¢˜ï¼‰
- "summary"ï¼ˆå·çš„ç®€è¦æè¿°ï¼Œ50-100å­—ï¼‰"""
        
        volumes_response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=volumes_prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        volumes_data = None
        if volumes_response.text:
            try:
                volumes_data = json.loads(volumes_response.text)
                if not isinstance(volumes_data, list):
                    volumes_data = None
            except:
                volumes_data = None
        
        if progress_callback:
            progress_callback.update(90, "å·ç»“æ„ç”Ÿæˆå®Œæˆï¼Œå¤„ç†ç»“æœ...")
        
        result = {
            "outline": full_outline,
            "volumes": volumes_data
        }
        
        if progress_callback:
            progress_callback.update(100, "ç”Ÿæˆå®Œæˆ")
        
        return result
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
        error_msg = str(e)
        if "location is not supported" in error_msg or "FAILED_PRECONDITION" in error_msg:
            friendly_msg = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ‰€åœ¨åœ°åŒºæš‚ä¸æ”¯æŒ Gemini API æœåŠ¡ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚"
            raise Exception(f"ç”Ÿæˆå¤§çº²å¤±è´¥: {friendly_msg}")
        raise Exception(f"ç”Ÿæˆå¤§çº²å¤±è´¥: {error_msg}")


def generate_volume_outline_stream(
    novel_title: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    characters: list,
    volume_index: int
):
    """ç”Ÿæˆå·è¯¦ç»†å¤§çº²ï¼ˆæµå¼ï¼‰"""
    try:
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        volume_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±å°è¯´ç­–åˆ’ï¼Œè¯·ä¸ºã€Š{novel_title}ã€‹çš„ç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆâ€œè¶³å¤Ÿè¯¦ç»†ã€å¯ç›´æ¥æ‹†åˆ†ä¸ºç« èŠ‚â€çš„å·è¯¦ç»†å¤§çº²ã€‚

ã€å…¨ä¹¦å®Œæ•´å¤§çº²ï¼ˆèŠ‚é€‰ï¼‰ã€‘
{full_outline[:2500]}

ã€æœ¬å·ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{volume_title}
{f'æè¿°ï¼š{volume_summary}' if volume_summary else ''}

ã€ä¸»è¦è§’è‰²ï¼ˆèŠ‚é€‰ï¼‰ã€‘
{characters_text}

ã€è¾“å‡ºè¦æ±‚ï¼ˆè¶Šå…·ä½“è¶Šå¥½ï¼‰ã€‘
1) æœ¬å·å®šä½
   - å·ä¸»é¢˜ã€ä¸»å†²çªã€æ ¸å¿ƒæ‚¬å¿µã€æƒ…ç»ªæ›²çº¿ã€ä¸å…¨ä¹¦ä¸»çº¿çš„æ‰¿æ¥ç‚¹
2) æœ¬å·ç»“æ„ï¼ˆèµ·æ‰¿è½¬åˆ/å¤šå¹•ï¼‰
   - è‡³å°‘åˆ—å‡ºï¼šå¯¼å…¥ã€ç¬¬ä¸€æ¬¡è½¬æŠ˜ã€ä¸­ç‚¹ã€ç¬¬äºŒæ¬¡è½¬æŠ˜ã€é«˜æ½®ã€æ”¶æŸï¼Œå¹¶å†™æ¸…â€œå› æœä¸ä»£ä»·â€
3) æœ¬å·å‰§æƒ…èŠ‚ç‚¹æ¸…å•ï¼ˆå¿…é¡»å¯æ‹†ç« ï¼‰
   - è‡³å°‘12-25ä¸ªèŠ‚ç‚¹ï¼ŒæŒ‰é¡ºåºç¼–å·ï¼Œæ¯ä¸ªèŠ‚ç‚¹åŒ…å«ï¼š
     * èŠ‚ç‚¹ç›®æ ‡/å¯¹æŠ—ç‚¹/å…³é”®è¡ŒåŠ¨/ç»“æœ/æ–°çš„ä¿¡æ¯æˆ–åè½¬/äººç‰©å¼§çº¿å˜åŒ–/ä¼ç¬”åŸ‹æˆ–æ”¶
4) æœ¬å·å…³é”®åœºæ™¯å»ºè®®ï¼ˆå¯é€‰ä½†å»ºè®®ï¼‰
   - åˆ—å‡ºè‡³å°‘8ä¸ªâ€œå¿…é¡»å‡ºç°çš„åœºæ™¯/å¯¹æ‰‹æˆâ€ï¼Œå†™æ¸…åœºæ™¯ç›®çš„ä¸å†²çª
5) å·æœ«çŠ¶æ€
   - æœ¬å·ç»“æŸæ—¶ï¼šä¸»è§’/åæ´¾/ä¸–ç•Œå±€åŠ¿åˆ†åˆ«å¤„äºä»€ä¹ˆæ–°çŠ¶æ€ï¼Ÿä¸‹ä¸€å·çš„çŸ›ç›¾ä»å“ªé‡Œè‡ªç„¶é•¿å‡ºï¼Ÿ

ã€å­—æ•°ä¸ç« èŠ‚è§„åˆ’ï¼ˆå¿…é¡»ç»™å‡ºå…·ä½“æ•°å­—ï¼‰ã€‘
- ä¼°ç®—æœ¬å·åˆç†å­—æ•°èŒƒå›´ï¼ˆé€šå¸¸æ¯å·15-30ä¸‡å­—ï¼Œå¯å› ç±»å‹è°ƒæ•´ï¼‰
- ç« èŠ‚æ•°å¿…é¡»æ˜¯å…·ä½“æ•°å­—ï¼Œä¸è¦èŒƒå›´
- è¯·åœ¨æœ«å°¾ç”¨å›ºå®šæ ¼å¼è¾“å‡ºï¼š
ã€å­—æ•°è§„åˆ’ã€‘ï¼šXX-XXä¸‡å­—
ã€ç« èŠ‚è§„åˆ’ã€‘ï¼šXXç« 
"""
        
        stream = client.models.generate_content_stream(
            model="gemini-3-pro-preview",
            contents=volume_prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 8192,
            }
        )
        
        for chunk in stream:
            if chunk.text:
                # æŒ‰ç…§ SSE æ ¼å¼è¿”å›æ•°æ®
                data = json.dumps({"chunk": chunk.text})
                yield f"data: {data}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'done': True})}\n\n"
                
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
        error_msg = str(e)
        if "location is not supported" in error_msg or "FAILED_PRECONDITION" in error_msg:
            friendly_msg = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ‰€åœ¨åœ°åŒºæš‚ä¸æ”¯æŒ Gemini API æœåŠ¡ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚"
            error_data = json.dumps({"error": friendly_msg})
            yield f"data: {error_data}\n\n"
            raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {friendly_msg}")
        
        # å‘é€é”™è¯¯ä¿¡æ¯
        error_data = json.dumps({"error": error_msg})
        yield f"data: {error_data}\n\n"
        raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {error_msg}")


def generate_volume_outline(
    novel_title: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    characters: list,
    volume_index: int,
    progress_callback=None
) -> str:
    """ç”Ÿæˆå·è¯¦ç»†å¤§çº²ï¼ˆéæµå¼ï¼Œè¿”å›å®Œæ•´æ–‡æœ¬ï¼‰"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹ç”Ÿæˆå·å¤§çº²...")
        
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        volume_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±å°è¯´ç­–åˆ’ï¼Œè¯·ä¸ºã€Š{novel_title}ã€‹çš„ç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆâ€œè¶³å¤Ÿè¯¦ç»†ã€å¯ç›´æ¥æ‹†åˆ†ä¸ºç« èŠ‚â€çš„å·è¯¦ç»†å¤§çº²ã€‚

ã€å…¨ä¹¦å®Œæ•´å¤§çº²ï¼ˆèŠ‚é€‰ï¼‰ã€‘
{full_outline[:2500]}

ã€æœ¬å·ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{volume_title}
{f'æè¿°ï¼š{volume_summary}' if volume_summary else ''}

ã€ä¸»è¦è§’è‰²ï¼ˆèŠ‚é€‰ï¼‰ã€‘
{characters_text}

ã€è¾“å‡ºè¦æ±‚ï¼ˆè¶Šå…·ä½“è¶Šå¥½ï¼‰ã€‘
1) æœ¬å·å®šä½
   - å·ä¸»é¢˜ã€ä¸»å†²çªã€æ ¸å¿ƒæ‚¬å¿µã€æƒ…ç»ªæ›²çº¿ã€ä¸å…¨ä¹¦ä¸»çº¿çš„æ‰¿æ¥ç‚¹
2) æœ¬å·ç»“æ„ï¼ˆèµ·æ‰¿è½¬åˆ/å¤šå¹•ï¼‰
   - è‡³å°‘åˆ—å‡ºï¼šå¯¼å…¥ã€ç¬¬ä¸€æ¬¡è½¬æŠ˜ã€ä¸­ç‚¹ã€ç¬¬äºŒæ¬¡è½¬æŠ˜ã€é«˜æ½®ã€æ”¶æŸï¼Œå¹¶å†™æ¸…â€œå› æœä¸ä»£ä»·â€
3) æœ¬å·å‰§æƒ…èŠ‚ç‚¹æ¸…å•ï¼ˆå¿…é¡»å¯æ‹†ç« ï¼‰
   - è‡³å°‘12-25ä¸ªèŠ‚ç‚¹ï¼ŒæŒ‰é¡ºåºç¼–å·ï¼Œæ¯ä¸ªèŠ‚ç‚¹åŒ…å«ï¼š
     * èŠ‚ç‚¹ç›®æ ‡/å¯¹æŠ—ç‚¹/å…³é”®è¡ŒåŠ¨/ç»“æœ/æ–°çš„ä¿¡æ¯æˆ–åè½¬/äººç‰©å¼§çº¿å˜åŒ–/ä¼ç¬”åŸ‹æˆ–æ”¶
4) æœ¬å·å…³é”®åœºæ™¯å»ºè®®ï¼ˆå¯é€‰ä½†å»ºè®®ï¼‰
   - åˆ—å‡ºè‡³å°‘8ä¸ªâ€œå¿…é¡»å‡ºç°çš„åœºæ™¯/å¯¹æ‰‹æˆâ€ï¼Œå†™æ¸…åœºæ™¯ç›®çš„ä¸å†²çª
5) å·æœ«çŠ¶æ€
   - æœ¬å·ç»“æŸæ—¶ï¼šä¸»è§’/åæ´¾/ä¸–ç•Œå±€åŠ¿åˆ†åˆ«å¤„äºä»€ä¹ˆæ–°çŠ¶æ€ï¼Ÿä¸‹ä¸€å·çš„çŸ›ç›¾ä»å“ªé‡Œè‡ªç„¶é•¿å‡ºï¼Ÿ

ã€å­—æ•°ä¸ç« èŠ‚è§„åˆ’ï¼ˆå¿…é¡»ç»™å‡ºå…·ä½“æ•°å­—ï¼‰ã€‘
- ä¼°ç®—æœ¬å·åˆç†å­—æ•°èŒƒå›´ï¼ˆé€šå¸¸æ¯å·15-30ä¸‡å­—ï¼Œå¯å› ç±»å‹è°ƒæ•´ï¼‰
- ç« èŠ‚æ•°å¿…é¡»æ˜¯å…·ä½“æ•°å­—ï¼Œä¸è¦èŒƒå›´
- è¯·åœ¨æœ«å°¾ç”¨å›ºå®šæ ¼å¼è¾“å‡ºï¼š
ã€å­—æ•°è§„åˆ’ã€‘ï¼šXX-XXä¸‡å­—
ã€ç« èŠ‚è§„åˆ’ã€‘ï¼šXXç« 
"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨AIç”Ÿæˆå·å¤§çº²...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=volume_prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 8192,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(90, "å·å¤§çº²ç”Ÿæˆå®Œæˆ")
        
        return response.text
                
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
        error_msg = str(e)
        if "location is not supported" in error_msg or "FAILED_PRECONDITION" in error_msg:
            friendly_msg = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ‰€åœ¨åœ°åŒºæš‚ä¸æ”¯æŒ Gemini API æœåŠ¡ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚"
            raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {friendly_msg}")
        raise Exception(f"ç”Ÿæˆå·å¤§çº²å¤±è´¥: {error_msg}")


def generate_chapter_outline(
    novel_title: str,
    genre: str,
    full_outline: str,
    volume_title: str,
    volume_summary: str,
    volume_outline: str,
    characters: list,
    volume_index: int,
    chapter_count: Optional[int] = None,
    previous_volumes_info: Optional[list] = None,
    future_volumes_info: Optional[list] = None
) -> list:
    """ç”Ÿæˆç« èŠ‚åˆ—è¡¨"""
    try:
        characters_text = "ã€".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰" for c in characters[:5]]) if characters else "æš‚æ— "
        
        # æå–å­—æ•°è§„åˆ’å’Œç« èŠ‚è§„åˆ’
        word_count_info = ""
        if volume_outline:
            import re
            word_match = re.search(r'ã€å­—æ•°è§„åˆ’ã€‘ï¼š\s*(\d+)[-~]?(\d+)?\s*ä¸‡å­—', volume_outline)
            if word_match:
                min_w = word_match.group(1)
                max_w = word_match.group(2) if word_match.group(2) else min_w
                word_count_info = f"\nå­—æ•°è§„åˆ’ï¼š{min_w}-{max_w}ä¸‡å­—" if max_w != min_w else f"\nå­—æ•°è§„åˆ’ï¼š{min_w}ä¸‡å­—"
        
        chapter_count_instruction = ""
        if chapter_count:
            chapter_count_instruction = f"""è¯·ä¸ºæœ¬å·ç”Ÿæˆ {chapter_count} ä¸ªç« èŠ‚ã€‚

ã€ç« èŠ‚ç”Ÿæˆç­–ç•¥ã€‘
1. é¦–å…ˆåŸºäºå·å¤§çº²ä¸­çš„ä¸»çº¿å‰§æƒ…ç”Ÿæˆç« èŠ‚ï¼ˆä¼˜å…ˆè¦†ç›–å·å¤§çº²ä¸­çš„æ‰€æœ‰ä¸»è¦æƒ…èŠ‚ç‚¹ï¼‰
2. å¦‚æœä¸»çº¿å‰§æƒ…ç”Ÿæˆçš„ç« èŠ‚æ•°ä¸è¶³ {chapter_count} ä¸ªï¼Œè¯·è¡¥å……æ”¯çº¿å‰§æƒ…ç« èŠ‚æ¥å‡‘è¶³æ•°é‡
3. æ”¯çº¿å‰§æƒ…ç« èŠ‚åº”è¯¥ï¼š
   - ä¸ä¸»çº¿å‰§æƒ…ç›¸å…³ï¼Œä½†ä¸èƒ½æ˜¯åç»­å·çš„å†…å®¹
   - å¯ä»¥æ˜¯è§’è‰²äº’åŠ¨ã€æ—¥å¸¸æå†™ã€ä¸–ç•Œè§‚å±•ç¤ºã€é…è§’æ•…äº‹ç­‰
   - å¿…é¡»åœ¨å½“å‰å·çš„æ—¶é—´çº¿å’Œæ•…äº‹èŒƒå›´å†…
   - åº”è¯¥ä¸°å¯Œæ•…äº‹çš„å±‚æ¬¡æ„Ÿï¼Œä¸è¦æ˜¾å¾—çªå…€
4. æœ€ç»ˆç”Ÿæˆçš„ç« èŠ‚æ€»æ•°å¿…é¡»è¾¾åˆ° {chapter_count} ä¸ª"""
        else:
            chapter_count_instruction = """è¯·ä»”ç»†åˆ†ææœ¬å·çš„è¯¦ç»†å¤§çº²ï¼Œæ ¹æ®ä»¥ä¸‹åŸåˆ™ç¡®å®šåˆé€‚çš„ç« èŠ‚æ•°é‡å¹¶ç”Ÿæˆç« èŠ‚åˆ—è¡¨ï¼š
ç« èŠ‚æ•°é‡åº”è¯¥ï¼š
1. ä¼˜å…ˆå‚è€ƒå·å¤§çº²ä¸­æ ‡æ³¨çš„ã€ç« èŠ‚è§„åˆ’ã€‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
2. æ ¹æ®å·å¤§çº²çš„å†…å®¹å¤æ‚åº¦å’Œå­—æ•°è§„åˆ’åˆç†åˆ†é…
3. ç¡®ä¿æ¯ä¸ªç« èŠ‚æœ‰è¶³å¤Ÿçš„å†…å®¹å’Œæƒ…èŠ‚å‘å±•ï¼ˆæ¯ç« 5000-8000å­—ï¼Œå³0.5-0.8ä¸‡å­—ï¼‰
4. å¦‚æœå¤§çº²ä¸­æœ‰å­—æ•°è§„åˆ’ï¼ŒæŒ‰ç…§æ¯ç« 5000-8000å­—çš„æ ‡å‡†è®¡ç®—ç« èŠ‚æ•°
5. å¦‚æœå¤§çº²ä¸­æ˜ç¡®æåˆ°äº†ç« èŠ‚æ•°ï¼Œè¯·å‚è€ƒè¯¥æ•°é‡
6. å¦‚æœå¤§çº²ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°ï¼Œè¯·æ ¹æ®æƒ…èŠ‚ç»“æ„åˆç†åˆ†é…ï¼ˆé€šå¸¸æ¯ç« å¯¹åº”ä¸€ä¸ªä¸»è¦äº‹ä»¶æˆ–æƒ…èŠ‚è½¬æŠ˜ç‚¹ï¼‰
7. å¦‚æœåŸºäºä¸»çº¿å‰§æƒ…ç¡®å®šçš„ç« èŠ‚æ•°åå°‘ï¼Œå¯ä»¥é€‚å½“å¢åŠ æ”¯çº¿å‰§æƒ…ç« èŠ‚ï¼ˆè§’è‰²äº’åŠ¨ã€æ—¥å¸¸æå†™ã€ä¸–ç•Œè§‚å±•ç¤ºç­‰ï¼‰æ¥ä¸°å¯Œå†…å®¹
8. ç« èŠ‚æ•°é‡åº”åœ¨åˆç†èŒƒå›´å†…ï¼ˆå»ºè®®6-30ç« ï¼‰"""
        
        volume_desc = f"å·æè¿°ï¼š{volume_summary[:200]}" if volume_summary else ""
        volume_outline_text = f"å·è¯¦ç»†å¤§çº²ï¼š{volume_outline[:2500]}" if volume_outline else ""
        
        # æ„å»ºå‰é¢å·çš„å‚è€ƒä¿¡æ¯ï¼ˆç”¨äºç¡®ä¿è¿è´¯æ€§ï¼‰
        previous_volumes_section = ""
        if volume_index > 0 and previous_volumes_info:
            previous_volumes_section = "\nã€å‰é¢å·çš„å‚è€ƒä¿¡æ¯ã€‘ï¼ˆç”¨äºç¡®ä¿æƒ…èŠ‚è¿è´¯ï¼Œä¸è¦é‡å¤è¿™äº›å†…å®¹ï¼‰\n"
            for prev_vol_info in previous_volumes_info:
                prev_vol_title = prev_vol_info.get("title", "")
                prev_vol_summary = prev_vol_info.get("summary", "")
                prev_chapters = prev_vol_info.get("chapters", [])
                
                previous_volumes_section += f"\n{prev_vol_title}ï¼š\n"
                if prev_vol_summary:
                    previous_volumes_section += f"  å·æè¿°ï¼š{prev_vol_summary[:200]}\n"
                if prev_chapters:
                    previous_volumes_section += "  å·²å‘ç”Ÿç« èŠ‚ï¼ˆæ ‡é¢˜ - æ‘˜è¦ï¼Œé¿å…é‡å¤ï¼‰ï¼š\n"
                    for ch in prev_chapters[:12]:
                        ch_title = ch.get("title", "")
                        ch_summary = (ch.get("summary", "") or "")[:120]
                        if ch_title and ch_summary:
                            previous_volumes_section += f"   - {ch_title}ï¼š{ch_summary}\n"
                        elif ch_title:
                            previous_volumes_section += f"   - {ch_title}\n"
            
            previous_volumes_section += "\né‡è¦ï¼šä½ å¿…é¡»æ‰¿æ¥è¿™äº›å·²å‘ç”Ÿäº‹ä»¶ï¼Œä½†ä¸è¦é‡å¤åŒç±»å†²çª/åŒä¸€äº‹ä»¶çš„å†è®²ä¸€éã€‚\n"

        # æ„å»ºåç»­å·çš„â€œç¦æ­¢æå‰â€ä¿¡æ¯ï¼ˆç”¨äºé¿å…ä¸²åˆ°åé¢å·ï¼‰
        future_volumes_section = ""
        if future_volumes_info:
            future_volumes_section = "\nã€åç»­å·è§„åˆ’ï¼ˆç¦æ­¢æå‰ä½¿ç”¨ï¼‰ã€‘\n"
            for next_vol in future_volumes_info[:3]:
                next_title = next_vol.get("title", "")
                next_summary = (next_vol.get("summary", "") or "")[:240]
                next_outline = (next_vol.get("outline", "") or "")[:500]
                if next_title:
                    future_volumes_section += f"\n{next_title}ï¼š\n"
                    if next_summary:
                        future_volumes_section += f"  è§„åˆ’ç®€ä»‹ï¼š{next_summary}\n"
                    if next_outline:
                        future_volumes_section += f"  è§„åˆ’è¦ç‚¹ï¼ˆæ‘˜è¦ï¼‰ï¼š{next_outline}\n"
            future_volumes_section += "\né‡è¦ï¼šä»¥ä¸Šå†…å®¹ä»…ç”¨äºâ€œé¿é›·â€ã€‚æœ¬å·ä¸å¾—å‡ºç°è¿™äº›å·çš„ä¸»è¦äº‹ä»¶ã€å…³é”®åè½¬æˆ–ç»“å±€ä¿¡æ¯ã€‚\n"
        
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹ç”Ÿæˆç« èŠ‚åˆ—è¡¨ï¼š

ã€âš ï¸ ä¸¥æ ¼é™åˆ¶ã€‘
ä½ åªèƒ½ç”Ÿæˆç¬¬ {volume_index + 1} å·ã€Š{volume_title}ã€‹çš„ç« èŠ‚åˆ—è¡¨ï¼Œç»å¯¹ä¸è¦åŒ…å«åç»­å·çš„æƒ…èŠ‚ï¼
æ‰€æœ‰ç« èŠ‚çš„å†…å®¹å¿…é¡»ä¸¥æ ¼é™åˆ¶åœ¨æœ¬å·çš„èŒƒå›´å†…ï¼Œä¸å¾—æ¶‰åŠåç»­å·çš„å‰§æƒ…å‘å±•æˆ–é¢„å‘Šï¼

ã€å°è¯´åŸºæœ¬ä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{novel_title}
ç±»å‹ï¼š{genre}
{previous_volumes_section}
{future_volumes_section}
ã€æœ¬å·è¯¦ç»†ä¿¡æ¯ã€‘ï¼ˆè¿™æ˜¯ä½ éœ€è¦ç”Ÿæˆç« èŠ‚çš„ä¾æ®ï¼‰
{volume_desc}
{volume_outline_text}{word_count_info}

ã€è§’è‰²ä¿¡æ¯ã€‘
{characters_text}

ã€ç”Ÿæˆè¦æ±‚ã€‘
{chapter_count_instruction}

ã€é‡è¦çº¦æŸã€‘
- æ¯ä¸€ç« å¿…é¡»èƒ½åœ¨â€œå·è¯¦ç»†å¤§çº²â€ä¸­æ‰¾åˆ°å¯¹åº”çš„æƒ…èŠ‚ç‚¹/æ®µè½ä¾æ®ï¼ˆä¸å…è®¸ç¼–é€ åç»­å·äº‹ä»¶ï¼‰
- chapter.title åªèƒ½å†™â€œç« èŠ‚æ ‡é¢˜æ–‡æœ¬â€ï¼Œä¸è¦åŒ…å«â€œç¬¬Xç« /ç¬¬ X ç« /1.â€ç­‰ç¼–å·å‰ç¼€ï¼ˆç¼–å·ç”±ç³»ç»Ÿç”Ÿæˆï¼‰
- å¦‚æœæä¾›äº†ã€å‰é¢å·çš„å‚è€ƒä¿¡æ¯ã€‘ï¼Œç¬¬1ç« å¿…é¡»æ‰¿æ¥ä¸Šä¸€å·ç»“å°¾çš„â€œçŠ¶æ€/çŸ›ç›¾/æ‚¬å¿µâ€ï¼Œä½†ä¸å¾—å¤è¿°ä¸Šä¸€å·å·²å‘ç”Ÿå†…å®¹ï¼ˆæœ€å¤šç”¨1-2å¥å¸¦è¿‡ï¼‰
- ç« èŠ‚æ ‡é¢˜å’Œæ‘˜è¦å¿…é¡»åªæ¶‰åŠæœ¬å·çš„å†…å®¹ï¼Œç»å¯¹ä¸è¦åŒ…å«åç»­å·çš„æƒ…èŠ‚
- ä¸å¾—åŒ…å«åç»­å·çš„å‰§æƒ…é¢„å‘Šã€æƒ…èŠ‚é“ºå«æˆ–ç»“å±€æš—ç¤ºï¼ˆåŒ…æ‹¬â€œä¸‹ä¸€å·/æœªæ¥/ç»ˆå±€/æœ€ç»ˆBOSSâ€ç­‰ï¼‰
- ç« èŠ‚é¡ºåºå¿…é¡»ä½“ç°æœ¬å·å†…éƒ¨çš„é€’è¿›ï¼šå¼•å…¥çŸ›ç›¾ â†’ å‡çº§æ¨è¿› â†’ é«˜æ½®/å…³é”®è½¬æŠ˜ â†’ æ”¶æŸ
- æœ¬å·çš„ä¸»è¦å†²çªåº”åœ¨æœ¬å·å†…é—­åˆï¼›å…è®¸ç•™ä¸‹â€œè½»å¾®æ‚¬å¿µâ€ï¼Œä½†ä¸å¾—æŠŠä¸‹ä¸€å·ä¸»çº¿æå‰å±•å¼€
- æ¯ä¸ªç« èŠ‚éƒ½åº”è¯¥æ˜¯æœ¬å·çš„ç‹¬ç«‹æ•…äº‹å•å…ƒ
- ç« èŠ‚çš„ç»“å°¾åº”è¯¥æ˜¯æœ¬å·çš„æƒ…èŠ‚æ”¶æŸï¼Œä¸è¦ä¸ºåç»­å·åŸ‹ä¸‹ä¼ç¬”
- å¦‚æœæœ¬å·å¤§çº²ä¸­æåˆ°äº†åç»­å·çš„å†…å®¹ï¼Œè¯·å¿½ç•¥å®ƒä»¬ï¼Œåªå…³æ³¨æœ¬å·çš„æè¿°
{f"- å¿…é¡»ä¸å‰é¢å·çš„æƒ…èŠ‚ä¿æŒè¿è´¯ï¼Œæ‰¿æ¥å‰é¢å·çš„æ•…äº‹å‘å±•" if volume_index > 0 else ""}
{f"- ä¸è¦é‡å¤å‰é¢å·å·²ç»å‘ç”Ÿçš„æƒ…èŠ‚å’Œäº‹ä»¶" if volume_index > 0 else ""}
{f"- æœ¬å·ç« èŠ‚åº”è¯¥æ˜¯åœ¨å‰é¢å·åŸºç¡€ä¸Šçš„è‡ªç„¶å»¶ç»­å’Œå‘å±•" if volume_index > 0 else ""}

ã€æ”¯çº¿å‰§æƒ…ä½¿ç”¨è¯´æ˜ã€‘
å¦‚æœä¸»çº¿å‰§æƒ…ç« èŠ‚æ•°é‡ä¸å¤Ÿï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç±»å‹çš„æ”¯çº¿å‰§æƒ…ç« èŠ‚æ¥è¡¥å……ï¼š
- è§’è‰²æ—¥å¸¸äº’åŠ¨ã€å¯¹è¯åœºæ™¯
- è§’è‰²å¿ƒç†æå†™ã€å›å¿†ç‰‡æ®µ
- ä¸–ç•Œè§‚ç»†èŠ‚å±•ç¤ºï¼ˆç¯å¢ƒã€è§„åˆ™ã€å†å²ç­‰ï¼‰
- é…è§’çš„æ•…äº‹çº¿æˆ–èƒŒæ™¯è¡¥å……
- æƒ…æ„Ÿçº¿çš„æ¨è¿›ï¼ˆå‹æƒ…ã€äº²æƒ…ã€çˆ±æƒ…ç­‰ï¼‰
- å°å†²çªçš„è§£å†³æˆ–æ–°çŸ›ç›¾çš„å¼•å…¥ï¼ˆä½†å¿…é¡»æ˜¯æœ¬å·èƒ½è§£å†³çš„ï¼‰
é‡è¦ï¼šæ”¯çº¿å‰§æƒ…å¿…é¡»åœ¨å½“å‰å·çš„æ—¶é—´èŒƒå›´å†…ï¼Œä¸èƒ½æ˜¯åç»­å·çš„å†…å®¹ï¼Œä¹Ÿä¸èƒ½é‡å¤å‰é¢å·å·²ç»å‘ç”Ÿçš„æƒ…èŠ‚ã€‚

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š"title"ï¼ˆæ ‡é¢˜ï¼Œä¸è¦å¸¦ç« èŠ‚ç¼–å·ï¼‰ã€"summary"ï¼ˆæ‘˜è¦ï¼‰ã€"aiPromptHints"ï¼ˆAIæç¤ºï¼‰ã€‚"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        chapters = json.loads(response.text)
        if not isinstance(chapters, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        return chapters
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")


def write_chapter_content_stream(
    novel_title: str,
    genre: str,
    synopsis: str,
    chapter_title: str,
    chapter_summary: str,
    chapter_prompt_hints: str,
    characters: list,
    world_settings: list,
    previous_chapters_context: Optional[str] = None,
    novel_id: Optional[str] = None,
    current_chapter_id: Optional[str] = None,
    db_session=None,
    forced_previous_chapter_context: Optional[str] = None
):
    """ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆæµå¼ï¼‰"""
    try:
        characters_text = "ï¼›".join([f"{c.get('name', '')}ï¼š{c.get('personality', '')}" for c in characters]) if characters else "æš‚æ— "
        world_text = "ï¼›".join([f"{w.get('title', '')}ï¼š{w.get('description', '')}" for w in world_settings]) if world_settings else "æš‚æ— "
        
        # è·å–å½“å‰å·ä¿¡æ¯ï¼ˆç”¨äºé™åˆ¶å†…å®¹èŒƒå›´ï¼‰
        current_volume_info = None
        current_volume_index = None
        if novel_id and db_session:
            try:
                from sqlalchemy.orm import Session
                from models import Chapter, Volume
                
                # å°è¯•é€šè¿‡chapter_idæŸ¥æ‰¾æ‰€å±çš„å·
                if current_chapter_id:
                    chapter_obj = db_session.query(Chapter).filter(Chapter.id == current_chapter_id).first()
                    if chapter_obj:
                        volume_obj = db_session.query(Volume).filter(Volume.id == chapter_obj.volume_id).first()
                        if volume_obj:
                            current_volume_info = {
                                "title": volume_obj.title,
                                "summary": volume_obj.summary or "",
                                "outline": volume_obj.outline or "",
                                "volume_index": volume_obj.volume_order
                            }
                            current_volume_index = volume_obj.volume_order
                else:
                    # å¦‚æœæ²’æœ‰chapter_idï¼Œå°è¯•é€šè¿‡ç« èŠ‚æ ‡é¢˜æŸ¥æ‰¾ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
                    chapter_obj = db_session.query(Chapter).join(Volume).filter(
                        Volume.novel_id == novel_id,
                        Chapter.title.like(f"%{chapter_title}%")
                    ).first()
                    if chapter_obj:
                        volume_obj = db_session.query(Volume).filter(Volume.id == chapter_obj.volume_id).first()
                        if volume_obj:
                            current_volume_info = {
                                "title": volume_obj.title,
                                "summary": volume_obj.summary or "",
                                "outline": volume_obj.outline or "",
                                "volume_index": volume_obj.volume_order
                            }
                            current_volume_index = volume_obj.volume_order
            except Exception as e:
                import logging
                logging.getLogger(__name__).warning(f"âš ï¸  è·å–å·ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # æ–°å¢ï¼šä½¿ç”¨å‘é‡æ£€ç´¢è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæä¾›äº† novel_id å’Œ db_sessionï¼‰
        if novel_id and db_session:
            try:
                from services.analysis.consistency_checker import ConsistencyChecker
                from services.analysis.content_similarity_checker import ContentSimilarityChecker
                
                # å¯é€‰ï¼šåœ¨ç”Ÿæˆå‰è¿›è¡Œç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆä»…è­¦å‘Šï¼Œä¸é˜»æ­¢ç”Ÿæˆï¼‰
                try:
                    similarity_checker = ContentSimilarityChecker()
                    similarity_result = similarity_checker.check_before_generation(
                        db=db_session,
                        novel_id=novel_id,
                        chapter_title=chapter_title,
                        chapter_summary=chapter_summary,
                        exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                        similarity_threshold=0.8
                    )
                    if similarity_result.get("has_similar_content"):
                        import logging
                        logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦è­¦å‘Š: {similarity_result.get('warnings', [])}")
                except Exception as e:
                    import logging
                    logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦æ£€æŸ¥å¤±è´¥ï¼ˆç»§ç»­ç”Ÿæˆï¼‰: {str(e)}")
                
                # è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡ï¼ˆåªè·å–å½“å‰å·åŠä¹‹å‰å·çš„ç« èŠ‚ï¼Œé¿å…åç»­å·å†…å®¹å¹²æ‰°ï¼‰
                checker = ConsistencyChecker()
                # å¦‚æœæœ‰å½“å‰å·ä¿¡æ¯ï¼ŒåªæŸ¥æ‰¾å½“å‰å·åŠä¹‹å‰å·çš„ç« èŠ‚
                exclude_volume_indices = None
                if current_volume_index is not None:
                    # æ’é™¤åç»­å·çš„ç« èŠ‚ï¼ˆé€šè¿‡æŸ¥è¯¢æ—¶æ’é™¤volume_order > current_volume_indexçš„ç« èŠ‚ï¼‰
                    # è¿™éœ€è¦åœ¨find_similar_chaptersä¸­å®ç°ï¼Œæš‚æ—¶å…ˆè·å–æ‰€æœ‰ï¼Œåç»­ä¼˜åŒ–
                    pass
                
                smart_context = checker.get_relevant_context_text(
                    db=db_session,
                    novel_id=novel_id,
                    current_chapter_title=chapter_title,
                    current_chapter_summary=chapter_summary,
                    exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                    max_chapters=5
                )
                
                if smart_context and smart_context.strip():
                    previous_chapters_context = smart_context
                    import logging
                    logging.getLogger(__name__).info(f"âœ… ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼Œæ‰¾åˆ° {len(smart_context.split('---'))} ä¸ªç›¸å…³ç« èŠ‚")
            except Exception as e:
                # å¦‚æœå‘é‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡ï¼Œä¸å½±å“ä¸»æµç¨‹
                import logging
                logging.getLogger(__name__).warning(f"âš ï¸  æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡: {str(e)}")
        
        # æ„å»ºå‰æ–‡ä¸Šä¸‹æ–‡éƒ¨åˆ†ï¼ˆå¢å¼ºç‰ˆï¼Œæ›´å¼ºè°ƒé¿å…é‡å¤ï¼‰
        previous_context_section = ""
        
        # ä¼˜å…ˆä½¿ç”¨å¼ºåˆ¶ä¸Šä¸‹æ–‡ï¼ˆå½“å‰ç« èŠ‚å†…å®¹ï¼‰
        if forced_previous_chapter_context and forced_previous_chapter_context.strip():
            previous_context_section = f"""

{forced_previous_chapter_context}

âš ï¸ é‡è¦ï¼šè¿™æ˜¯ä¸Šä¸€ç« çš„ç»“å°¾å†…å®¹ï¼Œä¸‹ä¸€ç« å¿…é¡»è‡ªç„¶æ‰¿æ¥è¿™ä¸ªç»“å°¾ï¼Œä¸èƒ½å‡ºç°æƒ…èŠ‚è·³è·ƒæˆ–é€»è¾‘æ–­è£‚ã€‚
"""
        
        # æ·»åŠ å‘é‡æ£€ç´¢çš„å…¶ä»–ç›¸å…³ç« èŠ‚ï¼ˆä½œä¸ºå‚è€ƒï¼‰
        if previous_chapters_context and previous_chapters_context.strip():
            if previous_context_section:
                previous_context_section += f"""

ã€ç›¸å…³å‰æ–‡å‚è€ƒã€‘ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦æ™ºèƒ½æ¨èçš„å…¶ä»–ç›¸å…³ç« èŠ‚ï¼‰ï¼š
{previous_chapters_context}
"""
            else:
                previous_context_section = f"""

ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦æ™ºèƒ½æ¨èçš„ç›¸å…³ç« èŠ‚ï¼‰ï¼š
{previous_chapters_context}
"""
        
        # æ·»åŠ é‡å¤å†…å®¹æ£€æŸ¥è¦æ±‚
        if previous_context_section:
            previous_context_section += """

ğŸš¨ ã€é‡å¤å†…å®¹æ£€æŸ¥è¦æ±‚ã€‘- å¿…é¡»ä¸¥æ ¼éµå®ˆï¼š
1. âŒ ç»å¯¹ç¦æ­¢ï¼šé‡å¤å‰æ–‡ä¸­å·²ç»å®Œæ•´æè¿°è¿‡çš„åœºæ™¯ã€äº‹ä»¶ã€å¯¹è¯
2. âŒ ç»å¯¹ç¦æ­¢ï¼šä½¿ç”¨ä¸å‰æ–‡ç›¸åŒçš„å™äº‹ç»“æ„ã€æå†™æ‰‹æ³•ã€è¯­è¨€é£æ ¼
3. âŒ ç»å¯¹ç¦æ­¢ï¼šè®©è§’è‰²é‡å¤åšè¿‡çš„äº‹æƒ…æˆ–è¯´è¿‡ç±»ä¼¼çš„è¯
4. âœ… æ­£ç¡®åšæ³•ï¼šå¦‚éœ€æåŠå‰æ–‡ï¼Œä»…ç”¨1-2å¥ç®€çŸ­è¿‡æ¸¡ï¼Œä¸å±•å¼€æå†™
5. âœ… æ­£ç¡®åšæ³•ï¼šæœ¬ç« å¿…é¡»æ¨è¿›å…¨æ–°æƒ…èŠ‚ï¼Œå±•ç°æ–°çš„å†²çªå’Œå‘å±•
6. âœ… æ­£ç¡®åšæ³•ï¼šé‡‡ç”¨ä¸åŒçš„å™è¿°è§†è§’ã€æƒ…ç»ªåŸºè°ƒã€æå†™é‡ç‚¹
7. âœ… æ­£ç¡®åšæ³•ï¼šç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æ ¸å¿ƒäº‹ä»¶ï¼Œä¸å‰æ–‡æ˜æ˜¾åŒºåˆ†

âš ï¸ æ³¨æ„ï¼šè¯·è®¤çœŸé˜…è¯»ä¸Šè¿°å‰æ–‡å†…å®¹ï¼Œç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨åŸåˆ›ä¸”ä¸å‰æ–‡è¿è´¯ã€‚
"""
        
        prompt = f"""è¯·ä¸ºå°è¯´ã€Š{novel_title}ã€‹åˆ›ä½œä¸€ä¸ªå®Œæ•´çš„ç« èŠ‚ã€‚

ã€ç« èŠ‚åŸºæœ¬ä¿¡æ¯ã€‘
- æ ‡é¢˜ï¼š{chapter_title}
- æƒ…èŠ‚æ‘˜è¦ï¼š{chapter_summary}
- å†™ä½œæç¤ºï¼š{chapter_prompt_hints}

ã€å°è¯´èƒŒæ™¯ä¿¡æ¯ã€‘
- å®Œæ•´ç®€ä»‹ï¼š{synopsis}
- æ¶‰åŠè§’è‰²ï¼š{characters_text}
- ä¸–ç•Œè§‚è§„åˆ™ï¼š{world_text}
{previous_context_section}

ã€åˆ›ä½œè¦æ±‚ã€‘
1. å­—æ•°è¦æ±‚ï¼š5000-8000å­—ï¼ˆæ­£æ–‡å†…å®¹ï¼Œå……å®é¥±æ»¡ï¼‰
2. æƒ…èŠ‚è¦æ±‚ï¼š
   - å¿…é¡»å®Œæ•´æ¨è¿›æœ¬ç« æƒ…èŠ‚ï¼Œæœ‰æ˜ç¡®çš„å¼€ç«¯ã€å‘å±•ã€é«˜æ½®ã€ç»“å°¾
   - æ ¸å¿ƒäº‹ä»¶å¿…é¡»ä¸å‰æ–‡ä¸åŒï¼Œé¿å…é‡å¤æƒ…èŠ‚
   - ç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æˆå‰§å†²çªå’Œæƒ…æ„Ÿå¼ åŠ›
3. å™äº‹è¦æ±‚ï¼š
   - é‡‡ç”¨é«˜æ–‡å­¦å“è´¨çš„æ²‰æµ¸å¼æè¿°
   - å¯¹è¯è¦ç”ŸåŠ¨è‡ªç„¶ï¼Œç¬¦åˆè§’è‰²æ€§æ ¼
   - ç»†èŠ‚æå†™ä¸°å¯Œï¼ˆç¯å¢ƒã€å¿ƒç†ã€åŠ¨ä½œã€ç¥æ€ï¼‰
   - å™äº‹èŠ‚å¥å¼ å¼›æœ‰åº¦ï¼Œé¿å…å¹³é“ºç›´å™
4. åŸåˆ›æ€§è¦æ±‚ï¼š
   - åœºæ™¯è®¾ç½®å¿…é¡»æ–°é¢–ç‹¬ç‰¹
   - è§’è‰²äº’åŠ¨æ–¹å¼è¦æœ‰å˜åŒ–
   - é¿å…ä½¿ç”¨å¥—è·¯åŒ–çš„è¡¨è¾¾å’Œæ¡¥æ®µ

âš ï¸ æœ€é‡è¦ï¼šè®¤çœŸé˜…è¯»ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼Œç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨åŸåˆ›ï¼Œä¸ä¸å‰æ–‡é‡å¤ï¼

ç°åœ¨è¯·å¼€å§‹åˆ›ä½œï¼Œä»…è¾“å‡ºç« èŠ‚æ­£æ–‡å†…å®¹ï¼ˆä¸è¦è¾“å‡ºæ ‡é¢˜ï¼‰ï¼š"""
        
        stream = client.models.generate_content_stream(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "temperature": 0.9,
                "max_output_tokens": 16384,
            }
        )
        
        for chunk in stream:
            if chunk.text:
                # æŒ‰ç…§ SSE æ ¼å¼è¿”å›æ•°æ®
                data = json.dumps({"chunk": chunk.text})
                yield f"data: {data}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'done': True})}\n\n"
                
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
        error_msg = str(e)
        if "location is not supported" in error_msg or "FAILED_PRECONDITION" in error_msg:
            friendly_msg = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ‰€åœ¨åœ°åŒºæš‚ä¸æ”¯æŒ Gemini API æœåŠ¡ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚"
            error_data = json.dumps({"error": friendly_msg})
            yield f"data: {error_data}\n\n"
            raise Exception(f"ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {friendly_msg}")
        
        # å‘é€é”™è¯¯ä¿¡æ¯
        error_data = json.dumps({"error": error_msg})
        yield f"data: {error_data}\n\n"
        raise Exception(f"ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {error_msg}")


def write_chapter_content(
    novel_title: str,
    genre: str,
    synopsis: str,
    chapter_title: str,
    chapter_summary: str,
    chapter_prompt_hints: str,
    characters: list,
    world_settings: list,
    previous_chapters_context: Optional[str] = None,
    novel_id: Optional[str] = None,
    current_chapter_id: Optional[str] = None,
    db_session=None,
    progress_callback=None,
    forced_previous_chapter_context: Optional[str] = None
) -> str:
    """ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆéæµå¼ï¼Œè¿”å›å®Œæ•´æ–‡æœ¬ï¼‰"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹ç”Ÿæˆç« èŠ‚å†…å®¹...")
        
        characters_text = "ï¼›".join([f"{c.get('name', '')}ï¼š{c.get('personality', '')}" for c in characters]) if characters else "æš‚æ— "
        world_text = "ï¼›".join([f"{w.get('title', '')}ï¼š{w.get('description', '')}" for w in world_settings]) if world_settings else "æš‚æ— "
        
        # ä½¿ç”¨å‘é‡æ£€ç´¢è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæä¾›äº† novel_id å’Œ db_sessionï¼‰
        if novel_id and db_session:
            try:
                from services.analysis.consistency_checker import ConsistencyChecker
                from services.analysis.content_similarity_checker import ContentSimilarityChecker
                
                # å¯é€‰ï¼šåœ¨ç”Ÿæˆå‰è¿›è¡Œç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆä»…è­¦å‘Šï¼Œä¸é˜»æ­¢ç”Ÿæˆï¼‰
                try:
                    similarity_checker = ContentSimilarityChecker()
                    similarity_result = similarity_checker.check_before_generation(
                        db=db_session,
                        novel_id=novel_id,
                        chapter_title=chapter_title,
                        chapter_summary=chapter_summary,
                        exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                        similarity_threshold=0.8
                    )
                    if similarity_result.get("has_similar_content"):
                        import logging
                        logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦è­¦å‘Š: {similarity_result.get('warnings', [])}")
                except Exception as e:
                    import logging
                    logging.getLogger(__name__).warning(f"âš ï¸  ç›¸ä¼¼åº¦æ£€æŸ¥å¤±è´¥ï¼ˆç»§ç»­ç”Ÿæˆï¼‰: {str(e)}")
                
                # è·å–æ™ºèƒ½ä¸Šä¸‹æ–‡
                checker = ConsistencyChecker()
                smart_context = checker.get_relevant_context_text(
                    db=db_session,
                    novel_id=novel_id,
                    current_chapter_title=chapter_title,
                    current_chapter_summary=chapter_summary,
                    exclude_chapter_ids=[current_chapter_id] if current_chapter_id else None,
                    max_chapters=5
                )
                
                if smart_context and smart_context.strip():
                    previous_chapters_context = smart_context
                    import logging
                    logging.getLogger(__name__).info(f"âœ… ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢ï¼Œæ‰¾åˆ° {len(smart_context.split('---'))} ä¸ªç›¸å…³ç« èŠ‚")
            except Exception as e:
                # å¦‚æœå‘é‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡ï¼Œä¸å½±å“ä¸»æµç¨‹
                import logging
                logging.getLogger(__name__).warning(f"âš ï¸  æ™ºèƒ½ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡: {str(e)}")
        
        # ä»chapter_prompt_hintsä¸­æå–ä¸Šä¸€ç« çš„é’©å­ï¼ˆå¦‚æœæœ‰ï¼‰
        previous_chapter_hook = ""
        if chapter_prompt_hints and "ã€ä¸Šä¸€ç« é’©å­ã€‘" in chapter_prompt_hints:
            hook_part = chapter_prompt_hints.split("ã€ä¸Šä¸€ç« é’©å­ã€‘")
            if len(hook_part) > 1:
                previous_chapter_hook = hook_part[-1].strip()
        elif chapter_prompt_hints and "ã€ä¸‹ä¸€ç« é’©å­ã€‘" in chapter_prompt_hints:
            # å…¼å®¹æ—§æ ¼å¼
            hook_part = chapter_prompt_hints.split("ã€ä¸‹ä¸€ç« é’©å­ã€‘")
            if len(hook_part) > 1:
                previous_chapter_hook = hook_part[-1].strip()
        
        # æ„å»ºå‰æ–‡ä¸Šä¸‹æ–‡éƒ¨åˆ†
        previous_context_section = ""
        if previous_chapters_context and previous_chapters_context.strip():
            previous_context_section = f"""

ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦æ™ºèƒ½æ¨èçš„ç›¸å…³ç« èŠ‚ï¼‰ï¼š
{previous_chapters_context}

ğŸš¨ ã€é‡å¤å†…å®¹æ£€æŸ¥è¦æ±‚ã€‘- å¿…é¡»ä¸¥æ ¼éµå®ˆï¼š
1. âŒ ç»å¯¹ç¦æ­¢ï¼šé‡å¤å‰æ–‡ä¸­å·²ç»å®Œæ•´æè¿°è¿‡çš„åœºæ™¯ã€äº‹ä»¶ã€å¯¹è¯
2. âŒ ç»å¯¹ç¦æ­¢ï¼šä½¿ç”¨ä¸å‰æ–‡ç›¸åŒçš„å™äº‹ç»“æ„ã€æå†™æ‰‹æ³•ã€è¯­è¨€é£æ ¼
3. âŒ ç»å¯¹ç¦æ­¢ï¼šè®©è§’è‰²é‡å¤åšè¿‡çš„äº‹æƒ…æˆ–è¯´è¿‡ç±»ä¼¼çš„è¯
4. âœ… æ­£ç¡®åšæ³•ï¼šå¦‚éœ€æåŠå‰æ–‡ï¼Œä»…ç”¨1-2å¥ç®€çŸ­è¿‡æ¸¡ï¼Œä¸å±•å¼€æå†™
5. âœ… æ­£ç¡®åšæ³•ï¼šæœ¬ç« å¿…é¡»æ¨è¿›å…¨æ–°æƒ…èŠ‚ï¼Œå±•ç°æ–°çš„å†²çªå’Œå‘å±•
6. âœ… æ­£ç¡®åšæ³•ï¼šé‡‡ç”¨ä¸åŒçš„å™è¿°è§†è§’ã€æƒ…ç»ªåŸºè°ƒã€æå†™é‡ç‚¹
7. âœ… æ­£ç¡®åšæ³•ï¼šç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æ ¸å¿ƒäº‹ä»¶ï¼Œä¸å‰æ–‡æ˜æ˜¾åŒºåˆ†

âš ï¸ æ³¨æ„ï¼šä¸Šè¿°å‰æ–‡æ˜¯é€šè¿‡AIè¯­ä¹‰åˆ†æè‡ªåŠ¨æ¨èçš„æœ€ç›¸å…³ç« èŠ‚ï¼Œè¯·è®¤çœŸé˜…è¯»å¹¶ç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨ä¸åŒã€‚
"""
        
        # æ„å»ºä¸Šä¸€ç« é’©å­éƒ¨åˆ†
        previous_hook_section = ""
        if previous_chapter_hook:
            previous_hook_section = f"""

ã€ä¸Šä¸€ç« ç»“å°¾é’©å­ã€‘ï¼ˆå¿…é¡»æ‰¿æ¥ï¼‰ï¼š
{previous_chapter_hook}

âš ï¸ é‡è¦ï¼šä¸Šä¸€ç« ç»“å°¾ç•™ä¸‹äº†è¿™ä¸ªæ‚¬å¿µ/è½¬æŠ˜ç‚¹ï¼Œæœ¬ç« å¼€å¤´å¿…é¡»è‡ªç„¶æ‰¿æ¥è¿™ä¸ªé’©å­ï¼Œä½†ä¸èƒ½ç›´æ¥é‡å¤ä¸Šä¸€ç« çš„ç»“å°¾å†…å®¹ã€‚åº”è¯¥ï¼š
1. ç”¨1-2å¥è¯ç®€çŸ­å‘¼åº”ä¸Šä¸€ç« çš„é’©å­
2. ç„¶åç«‹å³æ¨è¿›æ–°çš„æƒ…èŠ‚å‘å±•
3. ä¸è¦è®©è¯»è€…æ„Ÿè§‰é‡å¤æˆ–æ‹–æ²“
"""
        
        # æ¸…ç†chapter_prompt_hintsï¼Œç§»é™¤é’©å­æ ‡è®°ï¼ˆé’©å­å·²ç»åœ¨previous_hook_sectionä¸­å•ç‹¬å¤„ç†ï¼‰
        clean_prompt_hints = chapter_prompt_hints or ""
        if clean_prompt_hints:
            # ç§»é™¤é’©å­æ ‡è®°ï¼Œä¿ç•™å…¶ä»–æç¤º
            clean_prompt_hints = clean_prompt_hints.replace("ã€ä¸‹ä¸€ç« é’©å­ã€‘", "").replace("ã€ä¸Šä¸€ç« é’©å­ã€‘", "").strip()
            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            clean_prompt_hints = "\n".join([line for line in clean_prompt_hints.split("\n") if line.strip()])
        
        prompt = f"""è¯·ä¸ºå°è¯´ã€Š{novel_title}ã€‹åˆ›ä½œä¸€ä¸ªå®Œæ•´çš„ç« èŠ‚ã€‚

ã€ç« èŠ‚åŸºæœ¬ä¿¡æ¯ã€‘
- æ ‡é¢˜ï¼š{chapter_title}
- æƒ…èŠ‚æ‘˜è¦ï¼š{chapter_summary}
{f"- å†™ä½œæç¤ºï¼š{clean_prompt_hints}" if clean_prompt_hints else ""}
{previous_hook_section}

ã€å°è¯´èƒŒæ™¯ä¿¡æ¯ã€‘
- å®Œæ•´ç®€ä»‹ï¼š{synopsis}
- æ¶‰åŠè§’è‰²ï¼š{characters_text}
- ä¸–ç•Œè§‚è§„åˆ™ï¼š{world_text}
{previous_context_section}

ã€åˆ›ä½œè¦æ±‚ã€‘
1. å­—æ•°è¦æ±‚ï¼š5000-8000å­—ï¼ˆæ­£æ–‡å†…å®¹ï¼Œå……å®é¥±æ»¡ï¼‰
2. æƒ…èŠ‚è¦æ±‚ï¼š
   - å¿…é¡»å®Œæ•´æ¨è¿›æœ¬ç« æƒ…èŠ‚ï¼Œæœ‰æ˜ç¡®çš„å¼€ç«¯ã€å‘å±•ã€é«˜æ½®ã€ç»“å°¾
   - æ ¸å¿ƒäº‹ä»¶å¿…é¡»ä¸å‰æ–‡ä¸åŒï¼Œé¿å…é‡å¤æƒ…èŠ‚
   - ç¡®ä¿æœ¬ç« æœ‰ç‹¬ç‰¹çš„æˆå‰§å†²çªå’Œæƒ…æ„Ÿå¼ åŠ›
3. å™äº‹è¦æ±‚ï¼š
   - é‡‡ç”¨é«˜æ–‡å­¦å“è´¨çš„æ²‰æµ¸å¼æè¿°
   - å¯¹è¯è¦ç”ŸåŠ¨è‡ªç„¶ï¼Œç¬¦åˆè§’è‰²æ€§æ ¼
   - ç»†èŠ‚æå†™ä¸°å¯Œï¼ˆç¯å¢ƒã€å¿ƒç†ã€åŠ¨ä½œã€ç¥æ€ï¼‰
   - å™äº‹èŠ‚å¥å¼ å¼›æœ‰åº¦ï¼Œé¿å…å¹³é“ºç›´å™
4. åŸåˆ›æ€§è¦æ±‚ï¼š
   - åœºæ™¯è®¾ç½®å¿…é¡»æ–°é¢–ç‹¬ç‰¹
   - è§’è‰²äº’åŠ¨æ–¹å¼è¦æœ‰å˜åŒ–
   - é¿å…ä½¿ç”¨å¥—è·¯åŒ–çš„è¡¨è¾¾å’Œæ¡¥æ®µ

âš ï¸ æœ€é‡è¦ï¼šè®¤çœŸé˜…è¯»ã€å‰æ–‡å†…å®¹å‚è€ƒã€‘ï¼Œç¡®ä¿æœ¬ç« å†…å®¹å®Œå…¨åŸåˆ›ï¼Œä¸ä¸å‰æ–‡é‡å¤ï¼

ç°åœ¨è¯·å¼€å§‹åˆ›ä½œï¼Œä»…è¾“å‡ºç« èŠ‚æ­£æ–‡å†…å®¹ï¼ˆä¸è¦è¾“å‡ºæ ‡é¢˜ï¼‰ï¼š"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨AIç”Ÿæˆç« èŠ‚å†…å®¹...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "temperature": 0.9,
                "max_output_tokens": 16384,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(90, "ç« èŠ‚å†…å®¹ç”Ÿæˆå®Œæˆ")
        
        return response.text
                
    except Exception as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
        error_msg = str(e)
        if "location is not supported" in error_msg or "FAILED_PRECONDITION" in error_msg:
            friendly_msg = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ‰€åœ¨åœ°åŒºæš‚ä¸æ”¯æŒ Gemini API æœåŠ¡ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®ï¼Œæˆ–è€ƒè™‘ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ã€‚"
            raise Exception(f"ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {friendly_msg}")
        raise Exception(f"ç”Ÿæˆç« èŠ‚å†…å®¹å¤±è´¥: {error_msg}")


def summarize_chapter_content(chapter_title: str, chapter_content: str, max_len: int = 400) -> str:
    """
    ç”Ÿæˆç« èŠ‚æ‘˜è¦ï¼Œæ§åˆ¶åœ¨çº¦ max_len å­—ä»¥å†…ï¼›å¤±è´¥åˆ™è¿”å›æˆªæ–­å†…å®¹
    """
    if not chapter_content:
        return ""
    try:
        prompt = f"""è¯·ä¸ºä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆç®€æ˜æ‘˜è¦ï¼ˆ200-400å­—ï¼‰ï¼Œä¿ç•™ä¸»è¦å†²çªã€å…³é”®äº‹ä»¶ã€è§’è‰²çŠ¶æ€å˜åŒ–ã€‚ä»…è¾“å‡ºæ‘˜è¦æ–‡æœ¬ã€‚

ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
ç« èŠ‚å†…å®¹ï¼š
{chapter_content[:4000]}
"""
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "temperature": 0.25,
                "max_output_tokens": 512,
            },
        )
        summary = response.text or ""
        summary = summary.strip()
        if len(summary) > max_len:
            summary = summary[:max_len]
        return summary
    except Exception as e:
        logging.getLogger(__name__).warning(f"ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æˆªæ–­: {str(e)}")
        content = chapter_content.strip()
        if len(content) <= max_len:
            return content
        return content[:max_len - 10] + "..."


def generate_characters(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆè§’è‰²åˆ—è¡¨"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆè§’è‰²åˆ—è¡¨...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¸»è¦è§’è‰²åˆ—è¡¨ï¼ˆ3-8ä¸ªè§’è‰²ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªè§’è‰²ç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "name"ï¼ˆå§“åï¼‰
- "age"ï¼ˆå¹´é¾„ï¼‰
- "role"ï¼ˆè§’è‰²å®šä½ï¼Œå¦‚ï¼šä¸»è§’ã€åæ´¾ã€é…è§’ç­‰ï¼‰
- "personality"ï¼ˆæ€§æ ¼ç‰¹å¾ï¼‰
- "background"ï¼ˆèƒŒæ™¯æ•…äº‹ï¼‰
- "goals"ï¼ˆç›®æ ‡å’ŒåŠ¨æœºï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆè§’è‰²...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†è§’è‰²æ•°æ®...")
        
        characters = json.loads(response.text)
        if not isinstance(characters, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "è§’è‰²ç”Ÿæˆå®Œæˆ")
        
        return characters
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆè§’è‰²åˆ—è¡¨å¤±è´¥: {str(e)}")


def generate_world_settings(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆä¸–ç•Œè§‚è®¾å®š"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆä¸–ç•Œè§‚è®¾å®š...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆ5-10ä¸ªè®¾å®šï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªè®¾å®šç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "title"ï¼ˆè®¾å®šæ ‡é¢˜ï¼‰
- "category"ï¼ˆåˆ†ç±»ï¼šåœ°ç†ã€ç¤¾ä¼šã€é­”æ³•/ç§‘æŠ€ã€å†å²ã€å…¶ä»–ï¼‰
- "description"ï¼ˆè¯¦ç»†æè¿°ï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆä¸–ç•Œè§‚...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†ä¸–ç•Œè§‚æ•°æ®...")
        
        settings = json.loads(response.text)
        if not isinstance(settings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "ä¸–ç•Œè§‚ç”Ÿæˆå®Œæˆ")
        
        return settings
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆä¸–ç•Œè§‚è®¾å®šå¤±è´¥: {str(e)}")


def generate_timeline_events(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆé‡è¦æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆ5-10ä¸ªäº‹ä»¶ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:1000]}

è¯·ä¸ºæ¯ä¸ªäº‹ä»¶ç”Ÿæˆè¯¦ç»†ä¿¡æ¯ã€‚ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "time"ï¼ˆæ—¶é—´/å¹´ä»£ï¼‰
- "event"ï¼ˆäº‹ä»¶æ ‡é¢˜ï¼‰
- "impact"ï¼ˆäº‹ä»¶å½±å“å’Œåæœï¼‰"""
        
        if progress_callback:
            progress_callback.update(50, "æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆæ—¶é—´çº¿...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†æ—¶é—´çº¿æ•°æ®...")
        
        events = json.loads(response.text)
        if not isinstance(events, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ")
        
        return events
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆæ—¶é—´çº¿äº‹ä»¶å¤±è´¥: {str(e)}")


def generate_foreshadowings_from_outline(
    title: str,
    genre: str,
    synopsis: str,
    outline: str,
    progress_callback=None
) -> list:
    """ä»å¤§çº²ä¸­ç”Ÿæˆä¼ç¬”"""
    try:
        if progress_callback:
            progress_callback.update(20, "å¼€å§‹ç”Ÿæˆä¼ç¬”åˆ—è¡¨...")
        
        prompt = f"""åŸºäºä»¥ä¸‹å°è¯´ä¿¡æ¯ï¼Œç”Ÿæˆä¼ç¬”åˆ—è¡¨ï¼ˆ5-15ä¸ªä¼ç¬”ï¼‰ï¼š
æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}
å¤§çº²ï¼š{outline[:2000]}

è¯·åˆ†ææ•…äº‹å¤§çº²ï¼Œè¯†åˆ«å…¶ä¸­çš„ä¼ç¬”çº¿ç´¢ã€‚ä¼ç¬”æ˜¯æŒ‡åœ¨æ•…äº‹æ—©æœŸåŸ‹ä¸‹çš„çº¿ç´¢ï¼Œä¼šåœ¨åæœŸå¾—åˆ°å‘¼åº”æˆ–æ­ç¤ºã€‚

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "content"ï¼ˆä¼ç¬”å†…å®¹æè¿°ï¼Œ50-150å­—ï¼‰"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(80, "æ­£åœ¨å¤„ç†ä¼ç¬”æ•°æ®...")
        
        foreshadowings = json.loads(response.text)
        if not isinstance(foreshadowings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        if progress_callback:
            progress_callback.update(100, "ä¼ç¬”ç”Ÿæˆå®Œæˆ")
        
        return foreshadowings
        
    except Exception as e:
        raise Exception(f"ç”Ÿæˆä¼ç¬”å¤±è´¥: {str(e)}")


def modify_outline_by_dialogue(
    title: str,
    genre: str,
    synopsis: str,
    current_outline: str,
    characters: list,
    world_settings: list,
    timeline: list,
    user_message: str,
    progress_callback=None
) -> dict:
    """é€šè¿‡å¯¹è¯ä¿®æ”¹å¤§çº²å¹¶è”åŠ¨æ›´æ–°ç›¸å…³è®¾å®š"""
    try:
        if progress_callback:
            progress_callback.update(10, "å¼€å§‹åˆ†æä¿®æ”¹è¯·æ±‚...")

        def parse_requested_volume_count(message: str) -> Optional[int]:
            if not message:
                return None
            import re
            patterns = [
                r"(?:å¢åŠ |æ–°å¢|æ‰©å±•|æ·»åŠ |è¡¥å……|æ”¹ä¸º|æ”¹æˆ|è°ƒæ•´ä¸º|å˜ä¸º)\s*(\d{1,3})\s*(?:ä¸ª)?\s*å·",
                r"(\d{1,3})\s*(?:ä¸ª)?\s*å·",
            ]
            for pattern in patterns:
                match = re.search(pattern, message)
                if match:
                    try:
                        value = int(match.group(1))
                        if 1 <= value <= 200:
                            return value
                    except Exception:
                        continue
            return None

        def volumes_have_range_titles(volumes: list) -> bool:
            import re
            range_pattern = re.compile(r"(?:å·)?[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å0-9]+(?:è‡³|åˆ°|~|ï½|â€”|-)[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å0-9]+")
            for v in volumes:
                if not isinstance(v, dict):
                    continue
                title_text = (v.get("title") or "").strip()
                if not title_text:
                    continue
                if "è‡³" in title_text or "åˆ°" in title_text or "-" in title_text or "~" in title_text or "ï½" in title_text or "â€”" in title_text:
                    if range_pattern.search(title_text):
                        return True
            return False

        requested_volume_count = parse_requested_volume_count(user_message)
        
        # æ„å»ºæç¤ºè¯
        characters_text = "ï¼›".join([f"{c.get('name', '')}ï¼ˆ{c.get('role', '')}ï¼‰ï¼š{c.get('personality', '')}" for c in characters[:10]]) if characters else "æš‚æ— "
        world_text = "ï¼›".join([f"{w.get('title', '')}ï¼ˆ{w.get('category', '')}ï¼‰ï¼š{w.get('description', '')[:100]}" for w in world_settings[:10]]) if world_settings else "æš‚æ— "
        timeline_text = "ï¼›".join([f"[{t.get('time', '')}] {t.get('event', '')}" for t in timeline[:10]]) if timeline else "æš‚æ— "

        volume_count_constraint = ""
        if requested_volume_count:
            volume_count_constraint = f"""

ã€å·æ•°é‡ç¡¬çº¦æŸã€‘
ç”¨æˆ·è¦æ±‚å·æ•°ä¸º {requested_volume_count} å·ã€‚
å¦‚æœéœ€è¦è¾“å‡º "volumes"ï¼Œå¿…é¡»ä¸¥æ ¼è¾“å‡º {requested_volume_count} ä¸ªå·å¯¹è±¡ï¼Œä¸èƒ½å°‘ã€ä¸èƒ½å¤šã€‚
ä¸¥ç¦æŠŠå¤šä¸ªå·åˆå¹¶æˆä¸€ä¸ªå·åï¼ˆä¾‹å¦‚â€œå·åä¸€è‡³äºŒåâ€â€œç¬¬11-20å·â€ç­‰èŒƒå›´å·åï¼‰ã€‚
æ¯ä¸€å·å¿…é¡»æ˜¯ä¸€ä¸ªç‹¬ç«‹æ¡ç›®ï¼Œtitle å¿…é¡»æ˜¯å•å·åç§°ï¼Œsummary ä¸ºè¯¥å·ç®€ä»‹ï¼ˆ50-120å­—ï¼‰ã€‚"""
        
        prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±å°è¯´ç¼–è¾‘ï¼Œç”¨æˆ·æƒ³è¦ä¿®æ”¹å°è¯´ã€Š{title}ã€‹çš„å¤§çº²ã€‚

å½“å‰å°è¯´ä¿¡æ¯ï¼š
ç±»å‹ï¼š{genre}
ç®€ä»‹ï¼š{synopsis}

å½“å‰å®Œæ•´å¤§çº²ï¼š
{current_outline[:3000]}{'...' if len(current_outline) > 3000 else ''}

å½“å‰è§’è‰²åˆ—è¡¨ï¼š
{characters_text}

å½“å‰ä¸–ç•Œè§‚è®¾å®šï¼š
{world_text}

å½“å‰æ—¶é—´çº¿äº‹ä»¶ï¼š
{timeline_text}

ç”¨æˆ·ä¿®æ”¹è¯·æ±‚ï¼š{user_message}

è¯·æ ¹æ®ç”¨æˆ·çš„ä¿®æ”¹è¯·æ±‚ï¼Œç”Ÿæˆä¿®æ”¹åçš„å†…å®¹ã€‚ä½ éœ€è¦ï¼š
1. åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œç†è§£è¦ä¿®æ”¹çš„å†…å®¹
2. ç”Ÿæˆä¿®æ”¹åçš„å®Œæ•´å¤§çº²ï¼ˆä¿æŒåŸæœ‰ç»“æ„ï¼Œåªä¿®æ”¹éœ€è¦æ”¹å˜çš„éƒ¨åˆ†ï¼‰
3. å¦‚æœæ¶‰åŠåˆ°å·ç»“æ„çš„ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„å·åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
4. å¦‚æœæ¶‰åŠåˆ°è§’è‰²çš„æ–°å¢æˆ–ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„è§’è‰²åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
5. å¦‚æœæ¶‰åŠåˆ°ä¸–ç•Œè§‚çš„ä¿®æ”¹ï¼Œç”Ÿæˆæ›´æ–°åçš„ä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
6. å¦‚æœæ¶‰åŠåˆ°æ—¶é—´çº¿çš„è°ƒæ•´ï¼Œç”Ÿæˆæ›´æ–°åçš„æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆJSONæ•°ç»„æ ¼å¼ï¼‰
7. ç”Ÿæˆä¸€ä¸ªå˜æ›´è¯´æ˜åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå˜æ›´æè¿°å­—ç¬¦ä¸²ï¼‰
{volume_count_constraint}

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "outline": ä¿®æ”¹åçš„å®Œæ•´å¤§çº²ï¼ˆå­—ç¬¦ä¸²ï¼‰
- "volumes": ä¿®æ”¹åçš„å·åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "title" å’Œ "summary"ï¼‰
- "characters": ä¿®æ”¹åçš„è§’è‰²åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "name", "age", "role", "personality", "background", "goals"ï¼‰
- "world_settings": ä¿®æ”¹åçš„ä¸–ç•Œè§‚è®¾å®šåˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "title", "category", "description"ï¼‰
- "timeline": ä¿®æ”¹åçš„æ—¶é—´çº¿äº‹ä»¶åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œå¯é€‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "time", "event", "impact"ï¼‰
- "changes": å˜æ›´è¯´æ˜åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å­—ç¬¦ä¸²ï¼‰

åªè¿”å› JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
        
        if progress_callback:
            progress_callback.update(30, "æ­£åœ¨è°ƒç”¨ AI åˆ†æå¹¶ç”Ÿæˆä¿®æ”¹æ–¹æ¡ˆ...")
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.8,
                "max_output_tokens": 16384,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        if progress_callback:
            progress_callback.update(70, "æ­£åœ¨å¤„ç†ç”Ÿæˆç»“æœ...")
        
        result = json.loads(response.text)
        
        # ç¡®ä¿è¿”å›çš„æ•°æ®æ ¼å¼æ­£ç¡®
        if not isinstance(result, dict):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º JSON å¯¹è±¡")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if "outline" not in result:
            raise Exception("è¿”å›æ•°æ®ä¸­ç¼ºå°‘ outline å­—æ®µ")
        
        # ç¡®ä¿å¯é€‰å­—æ®µä¸ºåˆ—è¡¨æˆ– None
        if "volumes" in result and result["volumes"] is not None and not isinstance(result["volumes"], list):
            result["volumes"] = None
        if "characters" in result and result["characters"] is not None and not isinstance(result["characters"], list):
            result["characters"] = None
        if "world_settings" in result and result["world_settings"] is not None and not isinstance(result["world_settings"], list):
            result["world_settings"] = None
        if "timeline" in result and result["timeline"] is not None and not isinstance(result["timeline"], list):
            result["timeline"] = None
        if "changes" not in result or not isinstance(result.get("changes"), list):
            result["changes"] = []

        # å·åˆ—è¡¨æ ¡éªŒä¸ä¿®å¤ï¼šé¿å…â€œå·åä¸€è‡³äºŒåâ€è¿™ç§èŒƒå›´å·åä»¥åŠå·æ•°ä¸ç¬¦åˆç”¨æˆ·è¦æ±‚
        if requested_volume_count:
            volumes = result.get("volumes")
            if volumes is not None and isinstance(volumes, list):
                if len(volumes) != requested_volume_count or volumes_have_range_titles(volumes):
                    if progress_callback:
                        progress_callback.update(78, "æ£€æµ‹åˆ°å·åˆ—è¡¨ä¸ç¬¦åˆè¦æ±‚ï¼Œæ­£åœ¨è‡ªåŠ¨ä¿®å¤å·æ•°é‡/å·å‘½å...")

                    fix_prompt = f"""ç”¨æˆ·è¦æ±‚æŠŠã€Š{title}ã€‹çš„å·ç»“æ„è°ƒæ•´ä¸º {requested_volume_count} å·ã€‚

ä½ å°†æ”¶åˆ°å½“å‰æ¨¡å‹ç»™å‡ºçš„å·åˆ—è¡¨ï¼ˆå¯èƒ½æ•°é‡ä¸å¯¹ï¼Œæˆ–å‡ºç°â€œå·åä¸€è‡³äºŒåâ€è¿™ç±»èŒƒå›´å·åï¼‰ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼šè¾“å‡ºä¸¥æ ¼æ»¡è¶³è¦æ±‚çš„æ–°å·åˆ—è¡¨ï¼ˆJSONæ•°ç»„ï¼‰ã€‚

ç¡¬çº¦æŸï¼š
1. å¿…é¡»ä¸¥æ ¼è¾“å‡º {requested_volume_count} ä¸ªå¯¹è±¡
2. æ¯ä¸ªå¯¹è±¡å¿…é¡»åŒ…å« "title" ä¸ "summary"
3. title å¿…é¡»æ˜¯å•å·åç§°ï¼Œä¸¥ç¦èŒƒå›´/åˆå¹¶å·åï¼ˆä¾‹å¦‚â€œç¬¬11-20å·â€â€œå·åä¸€è‡³äºŒåâ€ç­‰ï¼‰
4. å·ä¸å·ä¹‹é—´è¦æœ‰æ¸…æ™°é€’è¿›ï¼Œsummary 50-120å­—

å½“å‰å·åˆ—è¡¨ï¼ˆå¾…ä¿®å¤ï¼‰ï¼š
{json.dumps(volumes, ensure_ascii=False)}

åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦è¾“å‡ºå…¶ä»–æ–‡å­—ã€‚"""

                    fix_response = client.models.generate_content(
                        model="gemini-3-pro-preview",
                        contents=fix_prompt,
                        config={
                            "response_mime_type": "application/json",
                            "temperature": 0.2,
                            "max_output_tokens": 8192,
                        },
                    )

                    if not fix_response.text:
                        raise Exception("å·åˆ—è¡¨ä¿®å¤å¤±è´¥ï¼šAPI è¿”å›ç©ºå“åº”")

                    fixed_volumes = json.loads(fix_response.text)
                    if not isinstance(fixed_volumes, list):
                        raise Exception("å·åˆ—è¡¨ä¿®å¤å¤±è´¥ï¼šè¿”å›æ ¼å¼ä¸æ˜¯ JSON æ•°ç»„")
                    if len(fixed_volumes) != requested_volume_count:
                        raise Exception(f"å·åˆ—è¡¨ä¿®å¤å¤±è´¥ï¼šæœŸæœ› {requested_volume_count} å·ï¼Œå®é™… {len(fixed_volumes)} å·")
                    if volumes_have_range_titles(fixed_volumes):
                        raise Exception("å·åˆ—è¡¨ä¿®å¤å¤±è´¥ï¼šä»åŒ…å«èŒƒå›´å·å")

                    result["volumes"] = fixed_volumes
                    result["changes"].append(f"å·²æŒ‰ç”¨æˆ·è¦æ±‚å°†å·ç»“æ„è§„èŒƒä¸º {requested_volume_count} å·ï¼Œå¹¶ä¿®å¤å·å‘½å/æ•°é‡ä¸ä¸€è‡´é—®é¢˜")
        
        if progress_callback:
            progress_callback.update(100, "ä¿®æ”¹æ–¹æ¡ˆç”Ÿæˆå®Œæˆ")
        
        return result
        
    except json.JSONDecodeError as e:
        raise Exception(f"è§£æ JSON å“åº”å¤±è´¥: {str(e)}")
    except Exception as e:
        raise Exception(f"ä¿®æ”¹å¤§çº²å¤±è´¥: {str(e)}")


def extract_foreshadowings_from_chapter(
    title: str,
    genre: str,
    chapter_title: str,
    chapter_content: str,
    existing_foreshadowings: list = None
) -> list:
    """ä»ç« èŠ‚å†…å®¹ä¸­æå–ä¼ç¬”"""
    try:
        existing_text = ""
        if existing_foreshadowings:
            existing_text = "\nå·²å­˜åœ¨çš„ä¼ç¬”ï¼š\n" + "\n".join([f"- {f.get('content', '')[:100]}" for f in existing_foreshadowings[:10]])
        
        prompt = f"""åŸºäºä»¥ä¸‹ç« èŠ‚å†…å®¹ï¼Œæå–æ–°å‡ºç°çš„ä¼ç¬”çº¿ç´¢ï¼ˆ0-5ä¸ªï¼‰ï¼š
å°è¯´æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
ç« èŠ‚å†…å®¹ï¼š{chapter_content[:3000]}
{existing_text}

è¯·ä»”ç»†åˆ†æç« èŠ‚å†…å®¹ï¼Œè¯†åˆ«ï¼š
1. æ–°å‡ºç°çš„å¯ç–‘çº¿ç´¢ã€æœªè§£ä¹‹è°œ
2. è§’è‰²çš„æš—ç¤ºæ€§è¯è¯­æˆ–è¡Œä¸º
3. ç¯å¢ƒä¸­çš„ç‰¹æ®Šç»†èŠ‚
4. çœ‹ä¼¼æ— æ„ä½†å¯èƒ½æœ‰æ·±æ„çš„æƒ…èŠ‚è®¾ç½®

æ³¨æ„ï¼š
- åªæå–æ˜æ˜¾å¯ä»¥ä½œä¸ºä¼ç¬”çš„å†…å®¹
- é¿å…ä¸å·²æœ‰ä¼ç¬”é‡å¤
- å¦‚æœç« èŠ‚ä¸­æ²¡æœ‰æ–°çš„ä¼ç¬”çº¿ç´¢ï¼Œè¿”å›ç©ºæ•°ç»„

ä»…è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ä»¥ä¸‹é”®ï¼š
- "content"ï¼ˆä¼ç¬”å†…å®¹æè¿°ï¼Œ50-150å­—ï¼‰"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0.7,
            }
        )
        
        if not response.text:
            raise Exception("API è¿”å›ç©ºå“åº”")
        
        foreshadowings = json.loads(response.text)
        if not isinstance(foreshadowings, list):
            raise Exception("è¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
        
        return foreshadowings
        
    except Exception as e:
        raise Exception(f"æå–ä¼ç¬”å¤±è´¥: {str(e)}")


def extract_next_chapter_hook(
    title: str,
    genre: str,
    chapter_title: str,
    chapter_content: str,
    next_chapter_title: Optional[str] = None,
    next_chapter_summary: Optional[str] = None
) -> str:
    """ä»ç« èŠ‚å†…å®¹ä¸­æå–ä¸‹ä¸€ç« é’©å­ï¼ˆæ‚¬å¿µã€è½¬æŠ˜ç‚¹ç­‰ï¼‰"""
    try:
        next_chapter_info = ""
        if next_chapter_title:
            next_chapter_info = f"\nä¸‹ä¸€ç« æ ‡é¢˜ï¼š{next_chapter_title}"
            if next_chapter_summary:
                next_chapter_info += f"\nä¸‹ä¸€ç« æ‘˜è¦ï¼š{next_chapter_summary}"
        
        prompt = f"""åŸºäºä»¥ä¸‹ç« èŠ‚å†…å®¹ï¼Œæå–æœ¬ç« ç»“å°¾çš„"ä¸‹ä¸€ç« é’©å­"ï¼ˆæ‚¬å¿µã€è½¬æŠ˜ç‚¹ã€æœªè§£ä¹‹è°œç­‰ï¼Œç”¨äºå¸å¼•è¯»è€…ç»§ç»­é˜…è¯»ï¼‰ï¼š

å°è¯´æ ‡é¢˜ï¼š{title}
ç±»å‹ï¼š{genre}
ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
ç« èŠ‚å†…å®¹ï¼ˆæœ€å2000å­—ï¼‰ï¼š{chapter_content[-2000:] if len(chapter_content) > 2000 else chapter_content}
{next_chapter_info}

è¯·åˆ†ææœ¬ç« ç»“å°¾ï¼Œæå–ï¼š
1. æœ¬ç« ç»“å°¾ç•™ä¸‹çš„æ‚¬å¿µæˆ–ç–‘é—®
2. ä¸‹ä¸€ç« å¯èƒ½çš„è½¬æŠ˜ç‚¹æˆ–å†²çª
3. è§’è‰²çŠ¶æ€æˆ–æƒ…èŠ‚å‘å±•çš„å…³é”®ä¿¡æ¯
4. å¸å¼•è¯»è€…ç»§ç»­é˜…è¯»çš„é’©å­

è¦æ±‚ï¼š
- é’©å­åº”è¯¥ç®€æ´æœ‰åŠ›ï¼ˆ50-200å­—ï¼‰
- åº”è¯¥ä¸ä¸‹ä¸€ç« å†…å®¹ç›¸å…³ï¼ˆå¦‚æœæä¾›äº†ä¸‹ä¸€ç« ä¿¡æ¯ï¼‰
- åº”è¯¥èƒ½å¤Ÿè‡ªç„¶å¼•å¯¼åˆ°ä¸‹ä¸€ç« çš„æƒ…èŠ‚

ä»…è¿”å›é’©å­æ–‡æœ¬å†…å®¹ï¼ˆä¸è¦åŒ…å«"é’©å­"ã€"æ‚¬å¿µ"ç­‰æ ‡ç­¾è¯ï¼‰ï¼Œç›´æ¥è¾“å‡ºæ–‡æœ¬ï¼š"""
        
        response = client.models.generate_content(
            model="gemini-3-pro-preview",
            contents=prompt,
            config={
                "temperature": 0.8,
                "max_output_tokens": 500,
            }
        )
        
        if not response.text:
            return ""
        
        hook = response.text.strip()
        return hook
        
    except Exception as e:
        import logging
        logging.getLogger(__name__).warning(f"æå–ä¸‹ä¸€ç« é’©å­å¤±è´¥: {str(e)}")
        return ""

